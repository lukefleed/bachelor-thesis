% --- SLIDE 20: Baseline: Graph Entropy H0(G) ---
\begin{frame}{Space Efficiency: Baseline Comparison}
    \framesubtitle{How Much Information is in the Graph?}
    To evaluate our structure's space, \alert{we need a baseline}.
    \begin{block}<1->{$0^{th}$-Order Graph Entropy $H_0(G)$}
        A theoretical lower bound for storing the \emph{entire} weighted DAG ($V, E, w$) losslessly.
        \[ H_0(G) = \underbrace{H_W(G)}_{\text{Cost for Weights}} + \underbrace{H_E(G)}_{\text{Cost for Topology (Edges)}} \]
    \end{block}
    \begin{itemize}
        \item<2-> $H_W(G) \approx \sum_{v \in V} \log(w(v)+1)$ bits (\emph{Minimal binary encoding for weights}).
        \item<3-> $H_E(G) \approx \log \binom{n(n-1)}{m}$ bits (\emph{Cost to choose $m=|E|$ edges out of all possible $n(n-1)$}).
    \end{itemize}
    \vspace{0.5em}
    \uncover<4->{\textbf{Any method saving the \emph{full} graph structure needs at least $H_0(G)$ bits!}}

\end{frame}


% --- SLIDE 21: Space Comparison - Key Numbers ---
\begin{frame}{Space Comparison: Succinct Structure vs. Baselines}
    \framesubtitle{Bitcoin DAG Example ($n \approx 22k, m \approx 50k$)}
    \begin{columns}[c] % Keep [t] for top alignment
        \begin{column}{0.5\textwidth} % Adjusted width potentially
            \centering
            \begin{tabular}{l r}
                \toprule
                \textbf{Method}                       & \textbf{Estimated Bits}          \\
                \midrule
                \textbf{Theoretical Lower Bound}      & \uncover<1->{\textbf{1,525,730}} \\
                \quad Weights $H_W(G)$                & \uncover<1->{60,824}             \\
                \quad Topology $H_E(G)$               & \uncover<1->{1,464,906}          \\
                \midrule
                \textit{Precomputed Rank Queries:}    &                                  \\
                \quad Explicit Binary Storage         & \uncover<2->{4,854,533}          \\
                \quad Elias-Fano Compressed           & \uncover<2->{2,211,849}          \\
                \midrule
                \textbf{Our Succinct DAG}             & \uncover<3->{\textbf{602,808}}   \\
                \quad Weights $\mathcal{W}$           & \uncover<3->{60,824}             \\
                \quad Successors $\Sigma$             & \uncover<3->{297,700}            \\
                \quad Assoc. Data $\mathcal{D}$ (RLE) & \uncover<3->{244,284}            \\
                \bottomrule
            \end{tabular}
            % Removed \end{center}
        \end{column}
        \begin{column}{0.5\textwidth} % Adjusted width to sum to 1.0
            % \begin{alertblock}<4->{Key Result}
            %     Our structure ($S(G)$) is $\approx$ \textbf{2.5x smaller} than the theoretical lower bound ($H_0(G)$) and $\approx$ \textbf{3.7x smaller} than compressed precomputation.
            % \end{alertblock}
            \begin{alertblock}<4->{Achieving Sub-Entropy Space: How?}
                Our structure is \textbf{lossy} regarding the full graph topology:
                \begin{itemize}
                    \item It \alert{does not store} the complete edge set.
                    \item It only stores the chosen successor $\sigma(v)$ for each implicit node (in $\Sigma$).
                \end{itemize}
                However, it is \textbf{lossless} for computing the specific \alert{Rank Query}.
            \end{alertblock}
        \end{column}
    \end{columns}
\end{frame}


% % --- SLIDE 22: Achieving Sub-Entropy Space: Why? (Corrected TikZ) ---
% \begin{frame}{Achieving Sub-Entropy Space: How is it Possible?}
%     \framesubtitle{Targeted Information Retention}

%     Why can our structure $S(G)$ use less space than the graph entropy $H_0(G)$?


%     \begin{center}
%         \begin{tikzpicture}[node distance=1cm, auto, >=latex,
%                 box/.style={rectangle, draw, thick, text centered, minimum height=3em, font=\sffamily, minimum width=5.5cm, align=center}, % Adjusted size and added align
%                 arrow/.style={->, thick}]

%             % Left Box: H0(G) stores the full Edge set E
%             \node [box, fill=red!10] (H0) {$H_0(G)$: Encodes \\ Full Graph $(V, \mathbf{E}, w)$};

%             % Right Box: S(G) stores only Successor info Sigma
%             \node [box, fill=green!10, right=2cm of H0] (SG) {$S(G)$: Encodes \\ $(\mathcal{W}, \Sigma, \mathcal{D})$};

%             % Labels above boxes
%             \node [above=0.3cm of H0, text width=5.5cm, align=center] {\small \textbf{Lossless Graph Encoding}};
%             \node [above=0.3cm of SG, text width=5.5cm, align=center] {\small \textbf{Our Succinct Structure}};

%         \end{tikzpicture}
%     \end{center}

%     \begin{alertblock}<1->{The Reason: Lossy Topology}
%         Our structure is \textbf{lossy} regarding the full graph topology:
%         \begin{itemize}
%             \item It \alert{does not store} the complete edge set $E$.
%             \item It only stores the chosen successor $\sigma(v)$ for each implicit node (in $\Sigma$).
%         \end{itemize}
%         However, it is \textbf{lossless} for computing the specific \alert{Rank Query}.
%     \end{alertblock}
%     % \uncover<2->{It retains only the information necessary for the target query, discarding unused topological details.}
% \end{frame}
