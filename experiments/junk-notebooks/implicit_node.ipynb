{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PER_RANK = 1  # Nodes/Rank: How 'fat' the DAG should be.\n",
    "MAX_PER_RANK = 5\n",
    "MIN_RANKS = 3     # Ranks: How 'tall' the DAG should be.\n",
    "MAX_RANKS = 5\n",
    "PERCENT = 30      # Chance of having an Edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dag(min_w, max_w, total_nodes): # min_w, max_w: node values range, total_nodes: total number of nodes\n",
    "    random.seed()  # Initialize the random number generator\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    current_nodes = 0 # Total number of nodes in the graph\n",
    "    ranks = [] # Number of nodes in each rank\n",
    "\n",
    "    # Generate ranks with nodes until the total number of nodes is reached\n",
    "    while current_nodes < total_nodes:\n",
    "        new_nodes = min(MAX_PER_RANK, total_nodes - current_nodes) # type: ignore # Number of nodes in the new rank\n",
    "        ranks.append(new_nodes) # Add the new rank to the list of ranks\n",
    "        current_nodes += new_nodes # Update the total number of nodes\n",
    "\n",
    "    nodes = 1 # Total number of nodes in the graph starts from 1\n",
    "\n",
    "    for rank in ranks:\n",
    "        for k in range(rank):\n",
    "            # Assign a random weight to each new node\n",
    "            node_weight = random.randint(min_w, max_w)\n",
    "            G.add_node(nodes + k, weight=node_weight)\n",
    "\n",
    "        # Edges from old nodes ('nodes') to new ones ('rank').\n",
    "        for j in range(nodes - 1): # Adjusted to start from 0\n",
    "            for k in range(rank):\n",
    "                if random.randint(0, 99) < PERCENT: # type: ignore # Randomly decide if there is an edge between the nodes\n",
    "                    G.add_edge(j + 1, k + nodes) # Adjusted to start from 1\n",
    "\n",
    "        nodes += rank  # Accumulate into old node set.\n",
    "\n",
    "    # remove isolated nodes\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    root_id = 0 # Root node is 0\n",
    "\n",
    "    roots = [node for node in G.nodes() if G.in_degree(node) == 0] # Find the root nodes\n",
    "    for _ in roots:\n",
    "        G.add_edge(root_id, _) # Add an edge from the root node to each root node\n",
    "\n",
    "    # add an attribute 'out' to the root node as a set containing 0\n",
    "    G.nodes[root_id]['out'] = []\n",
    "    G.nodes[root_id]['out'].append(0)\n",
    "    G.nodes[root_id]['weight'] = 0\n",
    "\n",
    "    return G\n",
    "\n",
    "def compute_node_out(G, node_id):\n",
    "    node_weight = G.nodes[node_id]['weight']\n",
    "    predecessors = list(G.predecessors(node_id))\n",
    "\n",
    "    node_out = []\n",
    "    for predecessor in predecessors:\n",
    "        predecessor_out = G.nodes[predecessor]['out']\n",
    "        # Extend the list instead of union\n",
    "        node_out.extend(predecessor_out)\n",
    "\n",
    "    # Ensure uniqueness and sort\n",
    "    node_out = sorted(set([x + node_weight for x in node_out]))\n",
    "    return node_out\n",
    "\n",
    "\n",
    "def optimal_father(G, node_id):\n",
    "    G.nodes[node_id]['optimal_father'] = None\n",
    "    successors = list(G.successors(node_id))\n",
    "    if len(successors) == 0:\n",
    "        return\n",
    "\n",
    "    max_out = -1\n",
    "    for successor in successors:\n",
    "        successor_out = G.nodes[successor]['out']\n",
    "        if len(successor_out) > max_out:\n",
    "            max_out = len(successor_out)\n",
    "            G.nodes[node_id]['optimal_father'] = successor\n",
    "\n",
    "def offset(G, node_id):\n",
    "    optimal_father = G.nodes[node_id]['optimal_father']\n",
    "    father_weight = G.nodes[optimal_father]['weight']\n",
    "    father_out = G.nodes[optimal_father]['out']\n",
    "    node_out = G.nodes[node_id]['out']\n",
    "\n",
    "    offset = [] #list of indexes of the father_out that are in node_out\n",
    "    for i in range(len(father_out)):\n",
    "        if father_out[i] - father_weight in node_out:\n",
    "            offset.append(i)\n",
    "\n",
    "    return offset\n",
    "\n",
    "\n",
    "def process_graph(G):\n",
    "    for node in list(nx.topological_sort(G))[1::]: # the root is already initialized with (0)\n",
    "        G.nodes[node]['out'] = compute_node_out(G, node)\n",
    "    for node in G.nodes():\n",
    "        optimal_father(G, node)\n",
    "    for node in G.nodes():\n",
    "        if G.nodes[node]['optimal_father'] is not None:\n",
    "            G.nodes[node]['offset'] = offset(G, node)\n",
    "        else:\n",
    "            G.nodes[node]['offset'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generate_dag(1, 10, 30)\n",
    "process_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, node_id, weight, successor_id=None, offset=None):\n",
    "        self.node_id = node_id\n",
    "        self.weight = weight\n",
    "        self.successor_id = successor_id\n",
    "        self.offset = offset\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Node(id={self.node_id}, weight={self.weight}, \"\n",
    "                f\"successor_id={self.successor_id}, offset={self.offset})\")\n",
    "\n",
    "class DAG:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "\n",
    "    def add_node(self, node_id, weight, successor_id=None, offset=None):\n",
    "        if node_id in self.nodes:\n",
    "            raise ValueError(f\"Node with id {node_id} already exists.\")\n",
    "        new_node = Node(node_id, weight, successor_id, offset)\n",
    "        self.nodes[node_id] = new_node\n",
    "\n",
    "    def remove_node(self, node_id):\n",
    "        if node_id not in self.nodes:\n",
    "            raise ValueError(f\"Node with id {node_id} does not exist.\")\n",
    "        del self.nodes[node_id]\n",
    "\n",
    "    def get_node(self, node_id):\n",
    "        return self.nodes.get(node_id)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join(str(node) for node in self.nodes.values())\n",
    "\n",
    "    # Query functions\n",
    "    def query(self, node_id, index):\n",
    "        node = self.get_node(node_id)\n",
    "        if node is None:\n",
    "            raise ValueError(f\"Node with id {node_id} does not exist.\")\n",
    "        if node.successor_id is None:\n",
    "            return node.offset[index]\n",
    "\n",
    "        sum_weights = 0\n",
    "        current_node = node\n",
    "        while current_node.successor_id is not None:\n",
    "            index = current_node.offset[index]  # Directly update index\n",
    "            current_node = self.get_node(current_node.successor_id)\n",
    "            sum_weights += current_node.weight\n",
    "        return current_node.offset[index] - sum_weights  # Use current_node directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id=1, weight=9, successor_id=30, offset=[3])\n",
      "Node(id=2, weight=3, successor_id=27, offset=[0])\n",
      "Node(id=3, weight=7, successor_id=26, offset=[0])\n",
      "Node(id=4, weight=3, successor_id=23, offset=[0])\n",
      "Node(id=5, weight=2, successor_id=28, offset=[0])\n",
      "Node(id=6, weight=6, successor_id=30, offset=[7])\n",
      "Node(id=7, weight=7, successor_id=27, offset=[10, 12])\n",
      "Node(id=8, weight=5, successor_id=30, offset=[2, 6])\n",
      "Node(id=9, weight=1, successor_id=27, offset=[4])\n",
      "Node(id=10, weight=5, successor_id=27, offset=[3, 4, 8])\n",
      "Node(id=11, weight=2, successor_id=27, offset=[1, 5, 6, 10, 12, 14])\n",
      "Node(id=12, weight=8, successor_id=26, offset=[6, 7, 8, 12, 13, 15])\n",
      "Node(id=13, weight=7, successor_id=27, offset=[6, 10, 11, 12, 15])\n",
      "Node(id=14, weight=10, successor_id=26, offset=[9, 13])\n",
      "Node(id=15, weight=8, successor_id=21, offset=[4, 5, 9, 14])\n",
      "Node(id=16, weight=1, successor_id=30, offset=[0, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 16, 17, 19])\n",
      "Node(id=17, weight=10, successor_id=29, offset=[4, 5, 10, 11, 12, 13, 14, 15, 18, 20, 23, 24])\n",
      "Node(id=18, weight=3, successor_id=21, offset=[2, 4, 5, 6, 7, 10, 12, 14])\n",
      "Node(id=19, weight=4, successor_id=30, offset=[1, 5, 8, 9, 11, 14, 16, 19, 20])\n",
      "Node(id=20, weight=7, successor_id=27, offset=[6, 11, 13, 15, 17, 18, 19, 20, 22, 24, 25, 27])\n",
      "Node(id=21, weight=8, successor_id=30, offset=[8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33])\n",
      "Node(id=22, weight=10, successor_id=30, offset=[7, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35])\n",
      "Node(id=23, weight=9, successor_id=30, offset=[6, 9, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])\n",
      "Node(id=24, weight=4, successor_id=30, offset=[4, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29])\n",
      "Node(id=25, weight=9, successor_id=None, offset=[18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 37, 40, 41])\n",
      "Node(id=26, weight=6, successor_id=None, offset=[13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48])\n",
      "Node(id=27, weight=1, successor_id=None, offset=[4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40])\n",
      "Node(id=28, weight=2, successor_id=None, offset=[4, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44])\n",
      "Node(id=29, weight=3, successor_id=None, offset=[6, 8, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45])\n",
      "Node(id=30, weight=2, successor_id=None, offset=[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44])\n",
      "Node(id=0, weight=0, successor_id=1, offset=[0])\n"
     ]
    }
   ],
   "source": [
    "dag = DAG()\n",
    "for node in G.nodes():\n",
    "    # if the node has a succesor, then do not represent its explicit set out, but just the offset\n",
    "    if G.nodes[node]['optimal_father'] is not None:\n",
    "        dag.add_node(node, G.nodes[node]['weight'], G.nodes[node]['optimal_father'], G.nodes[node]['offset'])\n",
    "    # if the node has no succesor, then represent its explicit set out\n",
    "    else:\n",
    "        dag.add_node(node, G.nodes[node]['weight'], None, G.nodes[node]['out'])\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in list(nx.topological_sort(G)):\n",
    "    for i in range(len(G.nodes[node]['out'])):\n",
    "        assert dag.query(node, i) == G.nodes[node]['out'][i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
