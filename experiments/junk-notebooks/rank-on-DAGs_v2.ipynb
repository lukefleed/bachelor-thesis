{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PER_RANK = 1  # Nodes/Rank: How 'fat' the DAG should be.\n",
    "MAX_PER_RANK = 5\n",
    "MIN_RANKS = 3     # Ranks: How 'tall' the DAG should be.\n",
    "MAX_RANKS = 5\n",
    "PERCENT = 30      # Chance of having an Edge.\n",
    "\n",
    "def generate_dag(min_w, max_w, total_nodes): # min_w, max_w: node values range, total_nodes: total number of nodes\n",
    "    random.seed()  # Initialize the random number generator\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    current_nodes = 0 # Total number of nodes in the graph\n",
    "    ranks = [] # Number of nodes in each rank\n",
    "\n",
    "    # Generate ranks with nodes until the total number of nodes is reached\n",
    "    while current_nodes < total_nodes:\n",
    "        new_nodes = min(MAX_PER_RANK, total_nodes - current_nodes) # Number of nodes in the new rank\n",
    "        ranks.append(new_nodes) # Add the new rank to the list of ranks\n",
    "        current_nodes += new_nodes # Update the total number of nodes\n",
    "\n",
    "    nodes = 1 # Total number of nodes in the graph starts from 1\n",
    "\n",
    "    for rank in ranks:\n",
    "        for k in range(rank):\n",
    "            # Assign a random weight to each new node\n",
    "            node_weight = random.randint(min_w, max_w)\n",
    "            G.add_node(nodes + k, weight=node_weight)\n",
    "\n",
    "        # Edges from old nodes ('nodes') to new ones ('rank').\n",
    "        for j in range(nodes - 1): # Adjusted to start from 0\n",
    "            for k in range(rank):\n",
    "                if random.randint(0, 99) < PERCENT: # Randomly decide if there is an edge between the nodes\n",
    "                    G.add_edge(j + 1, k + nodes) # Adjusted to start from 1\n",
    "\n",
    "        nodes += rank  # Accumulate into old node set.\n",
    "\n",
    "    # remove isolated nodes\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    root_id = 0 # Root node is 0\n",
    "\n",
    "    roots = [node for node in G.nodes() if G.in_degree(node) == 0] # Find the root nodes\n",
    "    for _ in roots:\n",
    "        G.add_edge(root_id, _) # Add an edge from the root node to each root node\n",
    "\n",
    "    # add an attribute 'out' to the root node as a set containing 0\n",
    "    G.nodes[root_id]['out'] = set()\n",
    "    G.nodes[root_id]['out'].add(0)\n",
    "    G.nodes[root_id]['weight'] = 0\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_out(G, node_id):\n",
    "    node_weight = G.nodes[node_id]['weight']\n",
    "    predecessors = list(G.predecessors(node_id))\n",
    "\n",
    "    node_out = set()\n",
    "    for predecessor in predecessors:\n",
    "        predecessor_out = G.nodes[predecessor]['out']\n",
    "        node_out = node_out.union(predecessor_out)\n",
    "\n",
    "    node_out = set([x + node_weight for x in node_out])\n",
    "    return node_out\n",
    "\n",
    "\n",
    "def rank(G, node_id):\n",
    "    rank =[]\n",
    "    for element in G.nodes[node_id]['out']:\n",
    "        rank.append((element - G.nodes[node_id]['weight'] + 1, element))\n",
    "\n",
    "    rank = sorted(rank, key=lambda x: x[0])\n",
    "\n",
    "    return rank\n",
    "\n",
    "\n",
    "def process_graph(G):\n",
    "    for node in list(nx.topological_sort(G))[1::]: # the root is already initialized with (0)\n",
    "        G.nodes[node]['out'] = compute_node_out(G, node)\n",
    "\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['optimal_father'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node 1 | weight: 4 \n",
      "out: [4]\n",
      "\n",
      "Node 2 | weight: 9 \n",
      "out: [9]\n",
      "\n",
      "Node 3 | weight: 1 \n",
      "out: [1]\n",
      "\n",
      "Node 4 | weight: 8 \n",
      "out: [8]\n",
      "\n",
      "Node 5 | weight: 6 \n",
      "out: [6]\n",
      "\n",
      "Node 6 | weight: 7 \n",
      "out: [11]\n",
      "\n",
      "Node 7 | weight: 1 \n",
      "out: [5, 7, 10]\n",
      "\n",
      "Node 8 | weight: 1 \n",
      "out: [5, 7, 9]\n",
      "\n",
      "Node 9 | weight: 8 \n",
      "out: [16]\n",
      "\n",
      "Node 10 | weight: 10 \n",
      "out: [11, 14]\n",
      "\n",
      "Node 11 | weight: 1 \n",
      "out: [7, 9]\n",
      "\n",
      "Node 12 | weight: 3 \n",
      "out: [7, 8, 9, 10, 12, 13, 14, 17, 19]\n",
      "\n",
      "Node 13 | weight: 8 \n",
      "out: [8]\n",
      "\n",
      "Node 14 | weight: 1 \n",
      "out: [2, 6, 8, 10, 12]\n",
      "\n",
      "Node 15 | weight: 10 \n",
      "out: [26]\n",
      "\n",
      "Node 16 | weight: 8 \n",
      "out: [10, 14, 15, 16, 17, 18, 20, 34]\n",
      "\n",
      "Node 17 | weight: 2 \n",
      "out: [4, 8, 10, 12, 13, 14, 16, 18]\n",
      "\n",
      "Node 18 | weight: 7 \n",
      "out: [12, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26]\n",
      "\n",
      "Node 19 | weight: 4 \n",
      "out: [15]\n",
      "\n",
      "Node 20 | weight: 1 \n",
      "out: [3, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
      "\n",
      "Node 21 | weight: 6 \n",
      "out: [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 40]\n",
      "\n",
      "Node 22 | weight: 8 \n",
      "out: [11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23]\n",
      "\n",
      "Node 23 | weight: 2 \n",
      "out: [4, 6, 7, 8, 9, 10, 12, 14]\n",
      "\n",
      "Node 24 | weight: 3 \n",
      "out: [4, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 37]\n",
      "\n",
      "Node 25 | weight: 10 \n",
      "out: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28]\n",
      "\n",
      "Node 26 | weight: 8 \n",
      "out: [12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34]\n",
      "\n",
      "Node 27 | weight: 5 \n",
      "out: [9, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 42]\n",
      "\n",
      "Node 28 | weight: 4 \n",
      "out: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 41]\n",
      "\n",
      "Node 29 | weight: 6 \n",
      "out: [8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32]\n",
      "\n",
      "Node 30 | weight: 2 \n",
      "out: [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 39, 42]\n",
      "\n",
      "Node 0 | weight: 0 \n",
      "out: [0]\n"
     ]
    }
   ],
   "source": [
    "# random generated DAG\n",
    "G = generate_dag(1, 10, 30) #(min weight, max weight, total number of nodes)\n",
    "process_graph(G)\n",
    "\n",
    "for node in G.nodes():\n",
    "    print(f\"\\nNode {node} | weight: {G.nodes[node]['weight']} \\nout: {sorted(list(G.nodes[node]['out']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressione con Elias-Fano\n",
    "\n",
    "### Compressione di un nodo espresso in maniera diretta\n",
    "\n",
    "Abbiamo una lista di interi strettamente crescenti: eseguiamo i seguenti step per comprimere la lista\n",
    "\n",
    "* **shift left**: sottraiamo ad ogni elemento il valore del primo elemento della lista\n",
    "    ```python\n",
    "    for i in range(1, n):\n",
    "        a[i] -= a[0]\n",
    "    ```\n",
    "    In questo modo il primo elemento sarà sempre 0.\n",
    "\n",
    "    > Costo: $O(n)$\n",
    "\n",
    "* **subtract rank:** sottraiamo ad ogni elemento (0-index) il numero di elementi minori di esso (che essendo strettamente crescente, equivale a sottraire l'indice)\n",
    "    ```python\n",
    "    for i in range(n):\n",
    "        a[i] -= i\n",
    "    ```\n",
    "    Questo possiamo farlo perché Elias-Fano funziona anche su sequenze di interi non decrescenti\n",
    "\n",
    "    > Costo: $O(n)$\n",
    "\n",
    "    \n",
    "* **flag bit**: dobbiamo salvare il primo elemento della lista originale per poter fare la decompressione. Se usiamo un encoding per intero come il $\\gamma$-encoding, non occupiamo troppo spazio. \n",
    "\n",
    "* **encoding**: Elias-Fano encoding per la lista di interi\n",
    "\n",
    "    > Costo: $O(n)$ compressione e decompressione\n",
    "\n",
    "* **RRR**: usiamo una struttura RRR per poter fare il rank e il select su bit array\n",
    "\n",
    "    > Costo: $o(n)$ in spazio e successivamente $O(1)$ per rank e select\n",
    "\n",
    "Per liste di grosse dimensioni e sopratutto per liste di interi molto grandi, la compressione sarà molto efficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappresentazione e compressione dei nodi in maniera indiretta rispetto ai successori\n",
    "\n",
    "Noi sappiamo che il set `out` associato ad ogni nodo è costruito prendendo l'unione dei set dei suoi predecessori ed aggiungendo il valore del nodo stesso ad ogni elemento\n",
    "\n",
    "--- \n",
    "\n",
    "La compressione però va fatta in funzione di uno dei successori del nodo (se presenti). Sappiamo che il set `out` del nodo sarà un sottoinsieme del set `out` del suo successore meno il suo valore. Quindi quello che possiamo fare per un nodo che vogliamo storare implicitamente è non storare in maniera esplicita il set `out` del nodo, ma solo i seguenti valori:\n",
    "\n",
    "* **node_weight (int)**: intero che rappresenta il valore del nodo\n",
    "* **successor_id (int)**: un riferimento al nodo padre  (ce ne saranno sicuramente di più, dobbiamo scegliere quello ottimale)\n",
    "* **offset (list of int)**: la posizione (0-index) dei valori del set `out` del nodo padre che sono presenti nel set `out` del nodo corrente\n",
    "\n",
    "In questo se vogliamo accedere al set `out` del nodo corrente, possiamo fare un `access` al set `out` del nodo padre e prendere gli elementi a partire dalla posizione `offset` fino alla fine. Con RRR possiamo fare il rank e il select per trovare la posizione di un elemento nel set `out` del nodo padre in $O(1)$.\n",
    "\n",
    "**OSSERVAZIONI:** Andando avanti nel dag, storare il set `out` esplicitamente diventa molto costoso in quanto potrebbero salire parecchio i valori facendo tutte le addizioni. In questo modo ad ogni nodo il massimo numero che può capitare è pari alla lunghezza del set `out` del nodo padre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dubbi\n",
    "\n",
    "* Come faccio a decidere quale è il padre ottimale? A questo punto è quello con la lunghezza minore del set `out`? \n",
    "* Come decido quali nodi comprimere in maniera diretta e quali in maniera indiretta? \n",
    "  * Facendo le cose a livelli di _topological generations_ a questo punto non ha senso (?) perché in quel caso potrei non storare nulla oltre il valore del nodo. E se mi viene chiesto il set out di un nodo implicito faccio la set union di tutti i predecessori e aggiungo il suo valore. Questo implicherebbe salvare i livelli uno si e uno no.\n",
    "  \n",
    "  > A grossi questa cosa non piace. Piuttosto propone questa sotto\n",
    "\n",
    "  * Come detto sopra fare la compressione di un nodo rispetto al suo successore. Il problema sta nel capire quali sono i nodi in cui storare esplicitamente il set 'out' e quali no. Si deve in qualche modo evitare - o trovare una soluzione - al caso in cui abbiamo un nodo implicito ed il suo padre ottimale è pure implicito e così via. Non vorrei dover andare troppo avanti nel grafo prima di trovare un nodo esplicito.\n",
    "    * Più che altro: se un nodo lo storo implicitamente, questo potrebbe essere l'optimal father di qualcun altro. \n",
    "  \n",
    "### Si potrebbe iniziare trovando delle euristiche per capire quali nodi comprimere in maniera diretta e quali in maniera indiretta.\n",
    "\n",
    "????????\n",
    "Quali euristiche prendo? Mi vengono in mente cose a livelli, ma livello per livello a sto punto faccio il ragionamento della set union dei precedenti ed ignoro il resto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
