{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PER_RANK = 1  # Nodes/Rank: How 'fat' the DAG should be.\n",
    "MAX_PER_RANK = 5\n",
    "MIN_RANKS = 3     # Ranks: How 'tall' the DAG should be.\n",
    "MAX_RANKS = 5\n",
    "PERCENT = 30      # Chance of having an Edge.\n",
    "\n",
    "def generate_dag(min_w, max_w, total_nodes): # min_w, max_w: node values range, total_nodes: total number of nodes\n",
    "    random.seed()  # Initialize the random number generator\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    current_nodes = 0 # Total number of nodes in the graph\n",
    "    ranks = [] # Number of nodes in each rank\n",
    "\n",
    "    # Generate ranks with nodes until the total number of nodes is reached\n",
    "    while current_nodes < total_nodes:\n",
    "        new_nodes = min(MAX_PER_RANK, total_nodes - current_nodes) # Number of nodes in the new rank\n",
    "        ranks.append(new_nodes) # Add the new rank to the list of ranks\n",
    "        current_nodes += new_nodes # Update the total number of nodes\n",
    "\n",
    "    nodes = 1 # Total number of nodes in the graph starts from 1\n",
    "\n",
    "    for rank in ranks:\n",
    "        for k in range(rank):\n",
    "            # Assign a random weight to each new node\n",
    "            node_weight = random.randint(min_w, max_w)\n",
    "            G.add_node(nodes + k, weight=node_weight)\n",
    "\n",
    "        # Edges from old nodes ('nodes') to new ones ('rank').\n",
    "        for j in range(nodes - 1): # Adjusted to start from 0\n",
    "            for k in range(rank):\n",
    "                if random.randint(0, 99) < PERCENT: # Randomly decide if there is an edge between the nodes\n",
    "                    G.add_edge(j + 1, k + nodes) # Adjusted to start from 1\n",
    "\n",
    "        nodes += rank  # Accumulate into old node set.\n",
    "\n",
    "    # remove isolated nodes\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    root_id = 0 # Root node is 0\n",
    "\n",
    "    roots = [node for node in G.nodes() if G.in_degree(node) == 0] # Find the root nodes\n",
    "    for _ in roots:\n",
    "        G.add_edge(root_id, _) # Add an edge from the root node to each root node\n",
    "\n",
    "    # add an attribute 'out' to the root node as a set containing 0\n",
    "    G.nodes[root_id]['out'] = set()\n",
    "    G.nodes[root_id]['out'].add(0)\n",
    "    G.nodes[root_id]['weight'] = 0\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_out(G, node_id):\n",
    "    node_weight = G.nodes[node_id]['weight']\n",
    "    predecessors = list(G.predecessors(node_id))\n",
    "\n",
    "    node_out = set()\n",
    "    for predecessor in predecessors:\n",
    "        predecessor_out = G.nodes[predecessor]['out']\n",
    "        node_out = node_out.union(predecessor_out)\n",
    "\n",
    "    node_out = set([x + node_weight for x in node_out])\n",
    "    return node_out\n",
    "\n",
    "\n",
    "def rank(G, node_id):\n",
    "    rank =[]\n",
    "    for element in G.nodes[node_id]['out']:\n",
    "        rank.append((element - G.nodes[node_id]['weight'] + 1, element))\n",
    "\n",
    "    rank = sorted(rank, key=lambda x: x[0])\n",
    "\n",
    "    return rank\n",
    "\n",
    "\n",
    "def process_graph(G):\n",
    "    for node in list(nx.topological_sort(G))[1::]: # the root is already initialized with (0)\n",
    "        G.nodes[node]['out'] = compute_node_out(G, node)\n",
    "\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['optimal_father'] = None\n",
    "\n",
    "    for node in list(nx.topological_sort(G))[1::]: # the root is already initialized with (0)\n",
    "        compute_optimal_father(G, node)\n",
    "\n",
    "def compute_optimal_father(G, node_id):\n",
    "    successors = list(G.successors(node_id))\n",
    "    optimal_father = min(successors, key=lambda x: len(G.nodes[x]['out']))\n",
    "    G.nodes[node_id]['optimal_father'] = optimal_father\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_633971/3701650105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# random generated DAG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(min weight, max weight, total number of nodes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocess_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_633971/270252254.py\u001b[0m in \u001b[0;36mprocess_graph\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopological_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# the root is already initialized with (0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcompute_optimal_father\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_optimal_father\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_633971/270252254.py\u001b[0m in \u001b[0;36mcompute_optimal_father\u001b[0;34m(G, node_id)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_optimal_father\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msuccessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0moptimal_father\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimal_father'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_father\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# random generated DAG\n",
    "G = generate_dag(1, 5, 100) #(min weight, max weight, total number of nodes)\n",
    "process_graph(G)\n",
    "\n",
    "for node in G.nodes():\n",
    "    print(f\"\\nNode {node} weight: {G.nodes[node]['weight']} \\nout: {sorted(list(G.nodes[node]['out']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressione con Elias-Fano\n",
    "\n",
    "### Compressione di un nodo espresso in maniera diretta\n",
    "\n",
    "Abbiamo una lista di interi strettamente crescenti: eseguiamo i seguenti step per comprimere la lista\n",
    "\n",
    "* **shift left**: sottraiamo ad ogni elemento il valore del primo elemento della lista\n",
    "    ```python\n",
    "    for i in range(1, n):\n",
    "        a[i] -= a[0]\n",
    "    ```\n",
    "    In questo modo il primo elemento sarà sempre 0.\n",
    "\n",
    "    > Costo: $O(n)$\n",
    "\n",
    "* **subtract rank:** sottraiamo ad ogni elemento (0-index) il numero di elementi minori di esso (che essendo strettamente crescente, equivale a sottraire l'indice)\n",
    "    ```python\n",
    "    for i in range(n):\n",
    "        a[i] -= i\n",
    "    ```\n",
    "    Questo possiamo farlo perché Elias-Fano funziona anche su sequenze di interi non decrescenti\n",
    "\n",
    "    > Costo: $O(n)$\n",
    "\n",
    "    \n",
    "* **flag bit**: dobbiamo salvare il primo elemento della lista originale per poter fare la decompressione. Se usiamo un encoding per intero come il $\\gamma$-encoding, non occupiamo troppo spazio. \n",
    "\n",
    "* **encoding**: Elias-Fano encoding per la lista di interi\n",
    "\n",
    "    > Costo: $O(n)$ compressione e decompressione\n",
    "\n",
    "* **RRR**: usiamo una struttura RRR per poter fare il rank e il select su bit array\n",
    "\n",
    "    > Costo: $o(n)$ in spazio e successivamente $O(1)$ per rank e select\n",
    "\n",
    "Per liste di grosse dimensioni e sopratutto per liste di interi molto grandi, la compressione sarà molto efficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappresentazione e compressione dei nodi in maniera indiretta rispetto ai successori\n",
    "\n",
    "Noi sappiamo che il set `out` associato ad ogni nodo è costruito prendendo l'unione dei set dei suoi predecessori ed aggiungendo il valore del nodo stesso ad ogni elemento\n",
    "\n",
    "--- \n",
    "\n",
    "La compressione però va fatta in funzione di uno dei successori del nodo (se presenti). Sappiamo che il set `out` del nodo sarà un sottoinsieme del set `out` del suo successore meno il suo valore. Quindi quello che possiamo fare per un nodo che vogliamo storare implicitamente è non storare in maniera esplicita il set `out` del nodo, ma solo i seguenti valori:\n",
    "\n",
    "* **node_weight (int)**: intero che rappresenta il valore del nodo\n",
    "* **successor_id (int)**: un riferimento al nodo padre  (ce ne saranno sicuramente di più, dobbiamo scegliere quello ottimale)\n",
    "* **offset (list of int)**: la posizione (0-index) dei valori del set `out` del nodo padre che sono presenti nel set `out` del nodo corrente\n",
    "\n",
    "In questo se vogliamo accedere al set `out` del nodo corrente, possiamo fare un `access` al set `out` del nodo padre e prendere gli elementi a partire dalla posizione `offset` fino alla fine. Con RRR possiamo fare il rank e il select per trovare la posizione di un elemento nel set `out` del nodo padre in $O(1)$.\n",
    "\n",
    "**OSSERVAZIONI:** Andando avanti nel dag, storare il set `out` esplicitamente diventa molto costoso in quanto potrebbero salire parecchio i valori facendo tutte le addizioni. In questo modo ad ogni nodo il massimo numero che può capitare è pari alla lunghezza del set `out` del nodo padre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dubbi\n",
    "\n",
    "* Come faccio a decidere quale è il padre ottimale? A questo punto è quello con la lunghezza minore del set `out`? \n",
    "* Come decido quali nodi comprimere in maniera diretta e quali in maniera indiretta? \n",
    "  * Facendo le cose a livelli di _topological generations_ a questo punto non ha senso (?) perché in quel caso potrei non storare nulla oltre il valore del nodo. E se mi viene chiesto il set out di un nodo implicito faccio la set union di tutti i predecessori e aggiungo il suo valore. Questo implicherebbe salvare i livelli uno si e uno no.\n",
    "  \n",
    "  > A grossi questa cosa non piace. Piuttosto propone questa sotto\n",
    "\n",
    "  * Come detto sopra fare la compressione di un nodo rispetto al suo successore. Il problema sta nel capire quali sono i nodi in cui storare esplicitamente il set 'out' e quali no. Si deve in qualche modo evitare - o trovare una soluzione - al caso in cui abbiamo un nodo implicito ed il suo padre ottimale è pure implicito e così via. Non vorrei dover andare troppo avanti nel grafo prima di trovare un nodo esplicito.\n",
    "    * Più che altro: se un nodo lo storo implicitamente, questo potrebbe essere l'optimal father di qualcun altro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0: [0]\n",
      "Level 1: [1, 2, 3, 4, 5, 6]\n",
      "Level 2: [8, 16, 10, 15, 7, 9]\n",
      "Level 3: [13, 17, 12, 14, 11]\n",
      "Level 4: [20, 22, 18, 19]\n",
      "Level 5: [23, 21, 24, 25, 30]\n",
      "Level 6: [28, 26, 27, 29, 31]\n",
      "Level 7: [40, 35, 34, 32, 33]\n",
      "Level 8: [37, 39, 36, 38]\n",
      "Level 9: [43, 42, 50, 41, 44, 45]\n",
      "Level 10: [46, 54, 47, 48, 49]\n",
      "Level 11: [52, 59, 51, 55, 53]\n",
      "Level 12: [58, 70, 56, 57, 64, 60, 65]\n",
      "Level 13: [62, 67, 61, 63, 75]\n",
      "Level 14: [66, 69, 68]\n",
      "Level 15: [74, 71, 72, 73, 76]\n",
      "Level 16: [79, 80, 77, 78]\n",
      "Level 17: [83, 85, 81, 82, 84]\n",
      "Level 18: [88, 86, 90, 87, 89, 94]\n",
      "Level 19: [93, 95, 91, 92, 96, 98]\n",
      "Level 20: [100, 99, 97]\n"
     ]
    }
   ],
   "source": [
    "gen = nx.topological_generations(G)\n",
    "\n",
    "for i, generation in enumerate(gen):\n",
    "    print(f\"Level {i}: {generation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
