% Chapter 1

\chapter{Introduction} % Chapter title

\label{ch:introduction} % For referencing the chapter elsewhere, use \autoref{ch:introduction}

\section{Why Succinct Data Structures?}
\label{sec:why_succinct}

Modern society generates and collects data at an unprecedented scale. From scientific endeavors capturing astronomical, climatological, and biological information, to the vast amounts of human-generated content like text, images, video, and social interactions, our ability to gather data often outpaces our capacity to effectively process it. While storage technology continues to advance rapidly, enabling us to archive enormous datasets, a critical bottleneck often arises in processing this data within the main memory (RAM) of computers. Accessing data in RAM is orders of magnitude faster (typically $\sim 10^5$ times) than accessing it from secondary storage like disks or even solid-state drives. Therefore, fitting the necessary data and auxiliary structures into main memory is crucial for the performance of many data-intensive applications.

However, the challenge is frequently not the size of the raw data itself, but the size of the data structures built on top of it to enable efficient querying and manipulation. Classical data structures, while offering fast operations, can sometimes consume significantly more space than the data they index - potentially one or two orders of magnitude larger. A compelling example is the human genome: while the sequence of approximately 3.3 billion bases can be stored in under 800 megabytes using a simple 2-bit encoding, a powerful structure like a suffix tree, essential for many sequence analysis tasks, can require over 30 gigabytes, exceeding the main memory capacity of typical desktop computers. \cite{navarro2016compact}

Several paradigms exist to cope with massive datasets, including efficient secondary-memory algorithms, streaming algorithms that process data in passes with limited memory, and distributed algorithms that partition data across multiple machines. Each approach has its strengths and weaknesses, often involving trade-offs in performance, accuracy, or applicability. Furthermore, the rise of memory-constrained devices like smartphones, sensors, and embedded systems within the Internet of Things presents scenarios where large secondary storage is unavailable, demanding extreme memory efficiency.

Data compression offers a way to reduce storage space but typically requires full decompression before the data can be used, making it unsuitable for random access or querying directly on the compressed form. This is where succinct data structures emerge as a powerful alternative. Situated at the intersection of Data Structures and Information Theory, succinct data structures aim to represent data using space close to the theoretical minimum (as defined by information-theoretic measures like entropy) while simultaneously supporting efficient queries directly on the compressed representation \cite{navarro2016compact}.

Essentially, succinct data structures strive to retain the operational benefits of traditional data structures - speeding up queries significantly compared to operating on raw data - while dramatically reducing their space footprint. By compressing both the data and the necessary indexing overhead, they allow larger datasets and more complex structures to fit within faster levels of the memory hierarchy (e.g., cache instead of RAM, or RAM instead of disk). This not only enables processing larger problems but can also lead to performance improvements due to better memory locality and reduced data transfer costs, even potentially benefiting distributed or streaming algorithms by increasing the effective memory available. The development of succinct structures for fundamental data types like bitvectors, sequences, trees, and graphs has led to a field with practical implementations and growing adoption.

\section{Results and Contributions}
\label{sec:results_contributions}

This thesis contributes to the field of succinct data structures by developing and analyzing a novel representation for node-weighted Directed Acyclic Graphs (DAGs), specifically designed to efficiently support path-based aggregation queries.

Building upon foundational concepts in data compression (\autoref{ch:Chapter2}) and established succinct techniques for sequences, particularly Rank and Select operations (\autoref{ch:Chapter3}), this work addresses the challenge of managing potentially complex path information in weighted DAGs. A key motivation stems from the observation that problems like querying occurrences within degenerate strings (\autoref{sec:degenerate_strings}) can be effectively modeled using weighted DAGs (\autoref{subsec:dag_from_degenerate}), but the application extends to other domains involving path analysis in acyclic graph structures.

The core technical contribution, presented in \autoref{chap:succinct_dags}, is a space-efficient DAG representation that supports a generalized \Rank{} query (\autoref{def:rank_dag}). This query aims to characterize the set of possible cumulative weights achievable on paths from a source vertex to a target vertex $N$, considering the contribution of $N$'s weight itself.

Our approach hinges on a strategic partitioning of the DAG's vertices into explicit nodes ($V_E$, typically sinks, whose path weight information is stored directly) and implicit nodes ($V_I$). For implicit nodes, the path weight information ($\mathcal{O}$-sets) is reconstructed on demand by following a path defined by a carefully chosen successor function $\sigma$ (\autoref{def:sigma_function}). This traversal relies on compact offset sequences ($\mathcal{I}_v$) stored for each implicit node $v$, which map indices in $\mathcal{O}_v$ to indices in the $\mathcal{O}$-set of its successor $\sigma(v)$. We provide algorithms (GetValue, GetOSet) for reconstructing $\mathcal{O}$-set information (\autoref{subsec:reconstructing_o_sets}) and computing the final \Rank{} query (\autoref{subsec:computing_rank}) based on this representation.

A crucial aspect is the analysis of compression strategies for the structure's components (\autoref{sec:compression_strategies}), including vertex weights, successor information, and the associated data sequences ($\mathcal{O}_v$ and $\mathcal{I}_v$). We leverage techniques like variable-length integer coding (potentially using implementations like those discussed in \autoref{app:compressed_intvec_engineering}), Elias-Fano coding for monotonic sequences (\autoref{sec:elias_fano_code}), and Run-Length Encoding (RLE) to minimize space.

Significantly, we demonstrate (\autoref{sec:below_entropy}) that the space usage of our proposed structure can be substantially lower than the theoretical $0^{th}$-order entropy bound required for a lossless representation of the entire input graph $G=(V, E, w)$. This efficiency is achieved because our structure is specifically tailored to the \Rank query and does not need to store the full graph topology (all edges $E$), thereby offering a highly space-efficient solution for its designated task compared to both general-purpose graph encodings and naive precomputation approaches.

\section{Structure of the thesis}
\label{sec:structure}

This thesis is organized as follows. Chapter \ref{ch:introduction}, the current chapter, provides the motivation for studying succinct data structures, outlines the main contributions of this thesis concerning succinct representations for weighted DAGs, and describes the overall structure of the document. Chapter \ref{ch:Chapter2} then lays the theoretical groundwork by reviewing fundamental concepts from information theory and essential compression techniques relevant for building compact representations, such as entropy, source coding, integer coding, and statistical coding. Following this, Chapter \ref{ch:Chapter3} introduces core building blocks used in many succinct data structures, focusing on Rank and Select operations, their implementation on bitvectors and Wavelet Trees, and their application to degenerate strings. The primary research contribution is presented in Chapter \ref{chap:succinct_dags}, which details the proposed succinct representation for weighted DAGs, including the mathematical framework, the structure itself, query algorithms, compression strategies, and space efficiency analysis. Chapter \ref{chap:conclusion} summarizes the findings and contributions, discusses limitations, and proposes future research directions aimed at enhancing query time predictability. Finally, Appendix \ref{app:compressed_intvec_engineering} provides practical implementation details for a compressed integer vector structure supporting efficient random access, complementing the theoretical discussion of compression techniques.
