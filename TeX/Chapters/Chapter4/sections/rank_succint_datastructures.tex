\section{Rank Methods for Subset Wavelet Trees} \label{sec:rank_succint_datastructures}
In \cite{SubsetWT} they compare 5 methods that supports \texttt{rank} and \texttt{rank-pairs} queries on small alphabet sequences (they need it to answer those queries on the sequences stored at the nodes of the subset wavelet tree).

\subsection{Wavelet Trees}

In their paper, Alanko et. al acknowledge the wavelet tree (\autoref{sec:wavelet_trees}) as the current go-to method for performing rank queries on sequences with non-binary alphabets. Wavelet trees will serve as a baseline for comparison with the other data structures they will evaluate. \vspace{0.4cm}

\noindent We have seen in \autoref{sec:wavelet_trees} that we can implement the wavelet trees in different ways, different choices can influence the trade-off between space usage and query speed. The authors experimented with two options: standard bitvectors (faster but larger, \autoref{sec:wavelet_trees}) and RRR bitvectors (smaller but slower, as explained in \autoref{subsec:compressing_bitvectors}). \vspace{0.4cm}

\noindent They specifically used implementations from the Succinct Data Structures Library (SDSL)\footnote{\url{https://github.com/simongog/sdsl-lite}} because they are known to be the fastest available WT implementations\footnote{The SDSL library does not provide an implementation for rank-pairs queries, but they are just the sum of two rank queries, so they can be easily implemented on top of the rank queries.}. \vspace{0.4cm}

\todo[inline]{I have a lot of doubts about this: why don't use an huffman shaped wavelet tree? Why didn't they try to adapt the wavelet tree to this type of queries?} \vspace{0.4cm}

\todo[inline]{There are multiple possible implementations of the WT in the SDSL (all immutable): Balanced wavelet (wt\_blcd), Balanced wavelet tree for integer alphabets (wt\_int), Wavelet matrix for integer alphabets (wm\_int), Huffman-shaped wavelet tree (wt\_huff), Hu-Tucker-shaped wavelet tree (wt\_hutu), Run-length compressed wavelet tree (wt\_rlmn), Fast select wavelet tree for integer alphabets (wt\_gmr). \vspace{0.4cm}

    \noindent TODO: Check their code to see which one they used both for the standard and the RRR version.}

\subsection{Scanning Rank}

The data structure comprises three layers to efficiently store and query the sequence \(X\).


\begin{itemize}
    \item \textbf{Highest Layer:} This layer divides \(X\) into superblocks of size \(s\) and maintains a table storing $rank(i,c)$ for each symbol $c \in \Sigma$ and each superblock starting at position \(i\). We can store these counts in a table of size $\sigma n / s$ words, so that we can access the count for any superblock $j$ at the column $j/s$ in constant time.
    \item \textbf{Middle Layer:} This layer further divides \(X\) into blocks of size \(b\), a divisor of \(s\). For each block starting at \(i\), precomputed counts of each symbol \(c\) are stored, specifically the occurrences of \(c\) in the range between the block's start and its enclosing superblock's start. With \(s=2^{32}\), these counts require 32 bits each.
    \item \textbf{Lowest Layer:} This layer directly stores the sequence, packing 32 base-4 symbols per 64-bit word. This layer occupies approximately $64 \cdot \lceil n/32 \rceil$ bits of space, where \(n\) is the length of \(X\).
\end{itemize}

\noindent A key optimization interleaves these counts with the actual sequence data within each block. In memory, a block consists of a 2-word header storing four (precomputed) counts, followed by \(b/64\) words containing the packed symbols. This interleaving let us store the lower and middle layers in a single array $A$ of $(2n/b + n/32)$ words (i.e., $64 \cdot (2n/b + n/32)$ bits) in memory. This ensures that the data structure is cache-friendly, as the entire structure can be loaded into memory in a single read operation.

\subsubsection*{Rank Queries}

\noindent To answer \(rank(i,c)\) queries with this structure, we follow these steps:
\begin{enumerate}
    \item Locate the block containing position \(i\).
    \item Retrieve the count for \(c\) from its header.
    \item Add this count to the corresponding count from the superblock table.
    \item Scan the block's data section to count occurrences of \(c\) up to position \(i\).
\end{enumerate}

\todo[inline]{TODO: add pseudocode for the rank query.}

\noindent This scanning typically involves examining whole words and possibly one partial word, which collectively contain the relevant part of the input sequence. Counting occurrences of bit patterns within these words is accelerated through bitwise operations. Notably, $rank-pair$ achieves a particularly fast implementation by using a single bitwise \texttt{AND}\footnote{\url{https://en.cppreference.com/w/cpp/language/operator_logical}} and a single \texttt{popcount}\footnote{\url{https://en.cppreference.com/w/cpp/numeric/popcount}} operation to count relevant symbol occurrences within a word.

\subsection{Sequence Splitting}

The authors propose a novel data structure designed to efficiently represent sequences with skewed distributions of symbols, such as those observed in subset sequences (TODO\todo{add a picture with the distributions}). The key idea is to exploit the dominance of certain symbols (e.g., 1 and 2 in base-4 sequences) by splitting the sequence into multiple components. \vspace{0.4cm}

\noindent Given a base-4 sequence \(X\) of length \(n\), we use the following components:
\begin{itemize}
    \item \textbf{Bitvector} \(\mathbf{L}\) representing the subsequence \(X_{1,2}\) (only symbols 1 and 2), where each bit indicates whether the corresponding symbol is 1 (0) or 2 (1)
    \item \textbf{Bitvector} \(\mathbf{R}\) representing the subsequence \(X_{0,3}\) (only symbols 0 and 3), with each bit indicating whether the corresponding symbol is 0 (0) or 3 (1)
    \item \textbf{Predecessor data structure} \(\mathbf{P}\) storing the positions \(i\) where \(X[i] \in \{0, 3\}\). Both \(L\) and \(R\) are equipped with rank support structures, enabling efficient rank queries.
\end{itemize}

\noindent In skewed distributions, most sets are singletons. This means \(X_{1,2}\) will be long, while \(X_{0,3}\), $P$, and $R$ will be relatively small. This compression is especially beneficial for memory-constrained scenarios. For base-3 sequences, the bitvector \(L\) is omitted, as the predecessor structure \(P\) already stores the indices of the non-singleton sets (where \(X[i] = 2\)).

\subsubsection*{Rank Queries}

Answering Rank queries on base-4 sequences, denoted as \(\textrm{rank}_X(i, c)\), involves two steps:

\begin{itemize}
    \item \textbf{Predecessor Query}: A predecessor query on \(P\) is performed for position \(i\), returning \(p\), the number of elements in \(P\) smaller than \(i\) (i.e., the rank of the predecessor of \(i\) in \(P\)).

    \item \textbf{Binary Rank Query:}  The result of the predecessor query, \(p\), is subtracted from \(i\) to obtain the appropriate index for a binary rank query. If \(c \in \{1, 2\}\), the query is performed on bitvector \(L\):
          \begin{align}
              \textrm{rank}_X(i, 1) & = \textrm{rank}_L(i-p, 0) \\
              \textrm{rank}_X(i, 2) & = \textrm{rank}_L(i-p, 1)
          \end{align}
          If \(c \in \{0, 3\}\), the query is performed on bitvector \(R\):
          \begin{align}
              \textrm{rank}_X(i, 0) & = \textrm{rank}_R(p, 0) \\
              \textrm{rank}_X(i, 3) & = \textrm{rank}_R(p, 1)
          \end{align}
\end{itemize}

\noindent Rank queries on base-3 sequences follow the same pattern as for base-4 sequences when dealing with singletons (\(x \in \{0,1\}\)). More precisely
\begin{align}
    \textrm{rank}_X(i, 0) & = \textrm{rank}_R(i-p, 0) \\
    \textrm{rank}_X(i, 1) & = \textrm{rank}_L(i-p, 1)
\end{align}
\noindent Since there's no second binary vector, the result of the predecessor query directly gives the rank for \(c=2\). \vspace{0.4cm}

\noindent On the other hand, with this data structure, \emph{rank-pair} queries can be answered more efficiently than two separate rank queries. This is because the predecessor query, which computes \(p\), needs to be performed only once for both symbols in the query.


\subsection{Generalized RRR}

For this final method, the authors present a generalization of the RRR entropy compressed bitvector (see \autoref{subsec:rank} and \cite{RRR2002}) to accommodate base-3 and base-4 sequences. While generalizations of RRR exist in the literature \cite{ferragina2007compressed}, this specific adaptation draws inspiration from the work of Navarro and Providel \cite{navarro2012fast}. \vspace{0.4cm}

\noindent Let \(X\) be a sequence of length \(n\) from a constant-sized alphabet \(\sigma\). To efficiently answer rank queries, we employ a three-level indexing structure similar to the basic binary RRR structure. We divide \(X\) into blocks of size \(b = O(\log n)\) and group them into superblocks of size \(B = O(\log n)\), where \(B\) is a multiple of \(b\). For each superblock, we precompute the counts of all symbols \(\sigma\) up to its starting position, storing these counts using \(O(\log n)\) bits each. For each block, we precompute the counts of all symbols \(\sigma\) within the block, storing them using \(O(\log \log n)\) bits each. The total space required for these precomputed counts is \(O(n \sigma \log \log n / \log n) = o(n)\) since \(\sigma\) is constant. \vspace{0.4cm}

\noindent A rank query \(\textrm{rank}(i, c)\) is then answered by: (i) Looking up the precomputed count of symbol \(c\) up to the start of the superblock containing position \(i\). (ii) Summing the precomputed counts of symbol \(c\) in the blocks preceding index \(i\) within the superblock. (iii) Counting the occurrences of symbol \(c\) in the prefix of length \(p = i \mod b\) within the block containing index \(i\). \vspace{0.4cm}


\noindent To determine the symbol count within a block's prefix, additional meta-information is encoded for decoding the block's symbol sequence. Then, we loop to count the occurrences of symbol \(c\) within the prefix of length $i \mod b$. The authors introduce a equivalence relation within all the possibile $\sigma^b$ blocks, such that two blocks are equivalent if and only if they contain tha same multiset of symbols\footnote{A multiset is a generalization of the concept of a set that, unlike a set, allows multiple instances of the same element.}. We can use the equivalence classes to efficiently choose the meta-information to store: each block will store the rank $r$ of the block within the lexicographically sorted list of all the blocks in the same equivalence class.

\subsubsection*{The \texttt{unrank} Function}

\noindent The class and the lexicographically rank of the block within the class completely determine the block's content (i.e the sequence of symbols it contains). This means that we can define a function
$$\textrm{unrank}(r,d_0, \dots, d_{\sigma-1})$$
that takes as input the lexicographic rank $r$ and the precomputed counts of the symbols in the block and returns the block's content. A naive implementation of this function would require to precompute and store all the possibile answers to the function, similarly to the third layer (the lookup table) of the RRR rank data structure. However, for large values of $b$ this is not feasible. \vspace{0.4cm}

\noindent Given the \emph{multinomial coefficient}
\begin{equation} \label{eq:multinomial}
    \binom{n}{d_0d_1 \dots d_{\sigma-1}} = \frac{n!}{d_0!d_1! \dots d_{\sigma-1}!}
\end{equation}
defined so that the value is $0$ if the sum of the $d_i$ is greater than $n$ or if any of the $d_i$ is negative. We can introduce the lexicographic rank of a block $c_0, c_1, \dots, c_{b-1}$ in the equivalence class as
\begin{equation} \label{eq:lexrank}
    \textrm{lexrank}(c_0, c_1, \dots, c_{b-1}) = \sum_{i=0}^{b-1} \sum_{j=0}^{c_i -1} \binom{b-1-i}{D_0(i) ~ \dots ~ D_j(i) -1 ~ \dots ~ D_{\sigma-1}(i)}
\end{equation}
where $D_k(i)$ is the number of occurrences of the symbol $k$ in the suffix of length $i$ of the block\footnote{$c_i, \dots, c_{b-1}$}. This function can be computed in $O(b \sigma)$ time. The term $-1$ that appears in the choices of the multinomial is there to avoid counting the block itself. \vspace{0.4cm}

\noindent Formula \ref{eq:lexrank} is a process that iterates through the symbols within a block from left to right, computing different ways to choose the remaining symbols in the block using the remaining counts, with the constraint that the complete block must be lexicographically smaller than the current block. The \texttt{unrank} function essentially reverses the \texttt{lexrank} function. This can be done by incrementally adding the multinomial terms in the inner sum until the total surpasses the target rank ($r$). At this point, the current symbol ($j$) is appended to the block's sequence, and the process moves on to the next iteration of the outer sum. \vspace{0.4cm}

\noindent Algorithm \ref{alg:base4unrank} provides a pseudocode implementation of this unranking process for a sequence based on a base-4 number system. The function prints the sequence of symbols in the block with rank $r$ among the class of blocks with symbol counts $d_0$, $d_1$, $d_2$, and $d_3$

\begin{algorithm}[h!]
    \caption{Base-4 block \emph{unranking} algorithm}
    \label{alg:base4unrank}
    \begin{algorithmic}
        \Function{Base4BlockUnrank}{$r$, $d_0$, $d_1$, $d_2$, $d_3$}
        \State $b \gets d_0 + d_1 + d_2 + d_3$ \Comment{Block size}
        \State $s \gets 0$ \Comment{Blocks counted so far}
        \For{$i = 0$ to $b-1$}
        \For{$j = 0$ to $3$} \Comment{$0$ to $\sigma - 1$}
        \State $d_j \gets d_j - 1$
        \State $count \gets \binom{b - 1 - i}{d_0, d_1, d_2, d_3}$
        \State $d_j \gets d_j + 1$
        \If{$s + count > r$}
        \State print $j$
        \State $d_j \gets d_j - 1$
        \State \textbf{break}
        \Else
        \State $s \gets s + count$
        \EndIf
        \EndFor
        \EndFor
        \EndFunction
    \end{algorithmic}
\end{algorithm}
