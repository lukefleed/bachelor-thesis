\chapter{Succinct Weighted DAGs for Path Queries}
\label{chap:succinct_dags}

The preceding chapters have established a foundation in data compression (\autoref{ch:Chapter2}) and succinct data structures, particularly focusing on Rank and Select operations over sequences (\autoref{ch:Chapter3}). These sequence-based tools provide efficient ways to handle queries on linear data.

Building upon this foundation, we now shift our focus to graph structures, specifically directed acyclic graphs (DAGs) where nodes carry weights. A key motivation for this shift comes from revisiting the \emph{degenerate string problem} introduced in \autoref{sec:degenerate_strings}. This problem can be viewed through a different lens, that of graph representation. As we detail below, a degenerate string and a target character can be naturally modeled as a specific type of weighted DAG.

\subsection*{Degenerate Strings as DAGs}
\label{subsec:dag_from_degenerate}

Given a degenerate string $X = X_1 X_2 \dots X_n$ over an alphabet $\Sigma$ (as defined in \autoref{sec:degenerate_strings}), we construct a weighted DAG $G_c = (V_c, E_c, w_c)$ for a specified character $c \in \Sigma$. This construction provides a formal mapping from the sequence structure to a graph structure, illustrating how the degenerate string problem can be viewed as a specific instance within a potentially broader graph-based framework.

First, we define the set of vertices $V_c$. Let $s$ be a unique source vertex. For each index $k$ ($1 \le k \le n$) and each character $a \in X_k$, we introduce a unique vertex, denoted abstractly as $v_{k,a}$. The vertex set $V_c$ is the union of the source and all such vertices:
\[ V_c = \{s\} \cup \{ v_{k,a} \mid 1 \le k \le n, a \in X_k \}. \]
These vertices $v_{k,a}$ represent the choice of character $a$ at position $k$ of the degenerate string.

The weight function $w_c: V_c \to \mathbb{N}_0$ is defined as follows: the weight of the source vertex $s$ is $w_c(s) = 0$. For any other vertex $v_{k,a} \in V_c \setminus \{s\}$, its weight depends on whether the character $a$ matches the target character $c$:
\[ w_c(v_{k,a}) = \begin{cases} 1 & \text{if } a = c \\ 0 & \text{if } a \neq c \end{cases}. \]
This function assigns a positive weight only to vertices corresponding to the specific character $c$ we are focusing on.

The edge set $E_c$ connects the source to the vertices representing the first set $X_1$, and subsequently connects vertices between adjacent positions $k$ and $k+1$:
\[ E_c = \{ (s, v_{1,a}) \mid a \in X_1 \} \cup \{ (v_{k,a}, v_{k+1,b}) \mid 1 \le k < n, a \in X_k, b \in X_{k+1} \}. \]
Since edges only connect vertices associated with index $k$ to vertices associated with index $k+1$, the graph $(V_c, E_c)$ contains no directed cycles and is therefore a DAG.

Figure \ref{fig:degenerate_example_tabular_v3} shows an example degenerate string. The weighted DAG $G_A$ derived from this string for character $c = \emph{A}$, following the construction detailed above, is illustrated in Figure \ref{fig:degenerate_dag_horizontal_v3}. In the figure, the notation $(k,a)$ inside a node identifies the vertex $v_{k,a}$.

% --- Figure for Degenerate String Example (Tabular Style) ---
\begin{figure}[htbp]
    \centering
    \begin{tabular}{c@{\hskip 0.5em}c@{\hskip 0.5em}c@{\hskip 0.5em}c@{\hskip 0.5em}c}
        $X = $                                                                           & $\Bigg\{\,\begin{matrix}\texttt{A}\\\texttt{C}\\\texttt{G}\end{matrix}\,\Bigg\}$ &
        $\Bigg\{\,\begin{matrix}\texttt{A}\\\texttt{T}\end{matrix}\,\Bigg\}$             &
        $\Bigg\{\,\begin{matrix}\texttt{T}\\\texttt{C}\\\texttt{A}\end{matrix}\,\Bigg\}$ &
        $\Bigg\{\,\begin{matrix}\texttt{A}\\\texttt{G}\end{matrix}\,\Bigg\}$                                                                                                                        \\
                                                                                         & $X_1$                                                                            & $X_2$ & $X_3$ & $X_4$
    \end{tabular}
    \caption{An example degenerate string $X = X_1 X_2 X_3 X_4$ over $\Sigma = \{A, C, G, T\}$.}
    \label{fig:degenerate_example_tabular_v3}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
            node distance=2.8cm and 1.0cm, % x distance and y distance
            node_style/.style={circle, draw, thick, minimum size=7mm, inner sep=0pt},
            weight_one/.style={node_style, fill=yellow!50},
            weight_zero/.style={node_style, fill=gray!20},
            source_node/.style={node_style, fill=red!60},
            edge_style/.style={->, >=latex, thin, gray},
            level_label/.style={font=\footnotesize, below=12mm of #1} % Style for level labels, increased spacing
        ]

        % Nodes arranged by level (k) vertically aligned
        \node[source_node] (s) at (0, 0) {$s$};

        % Vertices for k=1 (X1 = {A, C, G})
        \node[weight_one] (v1A) at (2, 2) {\tiny (1,A)}; \node[below=1pt of v1A] {\tiny w=1};
        \node[weight_zero](v1C) at (2, 0) {\tiny (1,C)}; \node[below=1pt of v1C] {\tiny w=0};
        \node[weight_zero](v1G) at (2,-2) {\tiny (1,G)}; \node[below=1pt of v1G] {\tiny w=0};
        % \node[level_label=v1C] (l1) {$k=1$}; % Label for level 1

        % Vertices for k=2 (X2 = {A, T})
        \node[weight_one] (v2A) at (4.8, 1) {\tiny (2,A)}; \node[below=1pt of v2A] {\tiny w=1};
        \node[weight_zero](v2T) at (4.8,-1) {\tiny (2,T)}; \node[below=1pt of v2T] {\tiny w=0};
        % \node[level_label=v2A] (l2) {$k=2$}; % Label for level 2

        % Vertices for k=3 (X3 = {T, C, A})
        \node[weight_zero] (v3A) at (7.6, 2) {\tiny (3,T)}; \node[below=1pt of v3A] {\tiny w=0};
        \node[weight_zero](v3C) at (7.6, 0) {\tiny (3,C)}; \node[below=1pt of v3C] {\tiny w=0};
        \node[weight_one](v3T) at (7.6,-2) {\tiny (3,A)}; \node[below=1pt of v3T] {\tiny w=1};
        % \node[level_label=v3C] (l3) {$k=3$}; % Label for level 3

        % Vertices for k=4 (X4 = {A, G})
        \node[weight_one] (v4A) at (10.4, 1) {\tiny (4,A)}; \node[below=1pt of v4A] {\tiny w=1};
        \node[weight_zero](v4G) at (10.4,-1) {\tiny (4,G)}; \node[below=1pt of v4G] {\tiny w=0};
        % \node[level_label=v4A] (l4) {$k=4$}; % Label for level 4

        % Edges
        % s to Level 1
        \foreach \v in {v1A, v1C, v1G} { \draw[edge_style] (s) -- (\v); }

        % Level 1 to Level 2 (All-to-all)
        \foreach \u in {v1A, v1C, v1G} {
                \foreach \v in {v2A, v2T} {
                        \draw[edge_style] (\u) -- (\v);
                    }
            }

        % Level 2 to Level 3 (All-to-all)
        \foreach \u in {v2A, v2T} {
                \foreach \v in {v3A, v3C, v3T} {
                        \draw[edge_style] (\u) -- (\v);
                    }
            }

        % Level 3 to Level 4 (All-to-all)
        \foreach \u in {v3A, v3C, v3T} {
                \foreach \v in {v4A, v4G} {
                        \draw[edge_style] (\u) -- (\v);
                    }
            }

    \end{tikzpicture}
    \caption{The weighted DAG $G_A$ derived from the degenerate string in Figure \ref{fig:degenerate_example_tabular_v3} for character $c=\emph{A}$. Nodes visually labeled $(k,a)$ represent the abstract vertices $v_{k,a}$. Nodes with $w_A(v_{k,a})=1$ are yellow; those with $w_A(v_{k,a})=0$ are gray. Edges represent the connections defined in $E_A$.}
    \label{fig:degenerate_dag_horizontal_v3}
\end{figure}

This graph-based perspective on degenerate strings serves as a concrete starting point for the core topic of this chapter: the development of succinct data structures for general node-weighted DAGs to support path-based queries. We address the challenge of representing an arbitrary DAG $G=(V, E, w)$, where each vertex $v \in V$ carries a non-negative integer weight $w(v)$, in a compressed format that efficiently supports queries related to cumulative path weights. Such weighted DAGs model various phenomena beyond degenerate strings. For example, in bioinformatics, pangenome graphs can be interpreted through this lens: if each node corresponds to a DNA sequence (a string over {A, C, G, T}), the weight $w(v)$ could represent the count of a specific nucleotide (e.g., \emph{A}) within that sequence; similarly for \emph{C}, \emph{G}, and \emph{T}.

Our primary focus is on generalizing the Rank query concept to this graph setting; the Select query, while definable, will not be treated further in this work. For a given vertex $N$, the Rank query aims to describe the set of possible cumulative weights achievable on paths originating from a designated source vertex $s$ and terminating at $N$.

The combinatorial complexity of paths in a DAG — potentially exponential in the number of vertices — makes naive approaches based on explicit path enumeration or storage infeasible for large graphs. This necessitates the development of a \emph{succinct} data structure. Our approach involves partitioning the vertices based on how their path weight information is represented: some vertices (\emph{explicit}) will store this information directly, while others (\emph{implicit}) will rely on indirect derivation through references facilitated by a carefully defined \emph{successor} relationship, as detailed in Section \ref{sec:succinct_dag_representation}.

\section{Mathematical Framework}
\label{sec:dag_defs}

To develop our data structure and associated algorithms, we first establish the necessary mathematical definitions and properties concerning weighted DAGs and path weights.

\subsection*{Weighted Directed Acyclic Graphs}
\label{subsec:dag_def}

We begin with the formal definition of the combinatorial structure central to this chapter.

\begin{definition}[Weighted DAG]
    \label{def:weighted_dag}
    A node-weighted Directed Acyclic Graph (weighted DAG) is a triple $G = (V, E, w)$, where:
    \begin{itemize}
        \item $V$ is a finite set of vertices. We typically identify $V$ with the set $\{0, 1, \dots, n-1\}$ where $n = |V|$, thereby implicitly defining a total order on the vertices.
        \item $E \subseteq V \times V$ is a set of directed edges such that the graph $(V, E)$ contains no directed cycles.
        \item $w: V \to \mathbb{N}_0$ is a weight function assigning a non-negative integer $w(v)$ to each vertex $v \in V$, where $\mathbb{N}_0 = \{0, 1, 2, \dots\}$.
    \end{itemize}
    For a vertex $v \in V$, we denote the set of its direct predecessors as $Pred(v) = \{u \in V \mid (u, v) \in E\}$ and the set of its direct successors as $Succ(v) = \{u \in V \mid (v, u) \in E\}$. A vertex $v$ with $Succ(v) = \emptyset$ is termed a \emph{sink} vertex.
\end{definition}

This definition provides the fundamental object of study. We will often rely on the acyclic property, which guarantees the existence of topological orderings of the vertices.

\begin{assumption}[Unique Source]
    \label{ass:unique_source}
    Without loss of generality, we assume that the DAG $G$ possesses a unique source vertex $s \in V$ characterized by $Pred(s) = \emptyset$. If multiple sources exist in the original graph, a standard preprocessing step involves introducing a virtual source vertex $s'$ with $w(s')=0$ and adding edges $(s', v)$ for all original source vertices $v$. Throughout this work, we assume such a transformation has been applied if necessary, and we identify the unique source with vertex $s=0$, setting $w(s)=0$.
\end{assumption}

Having defined the graph structure, we now define paths and their associated weights, which are central to the queries we aim to support.

\begin{definition}[Paths and Path Weights]
    \label{def:paths_weights}
    A path $P$ from a vertex $u$ to a vertex $v$ in $G$ is a sequence of vertices $P = (v_0, v_1, \dots, v_k)$ such that $v_0 = u$, $v_k = v$, and $(v_{j-1}, v_j) \in E$ for all $1 \le j \le k$. The length of the path $P$ is $k$, the number of edges. Let $Path(s, v)$ denote the set of all paths originating from the unique source $s$ and terminating at $v$. The cumulative weight relevant for our Rank query, denoted $W'(P)$, for a path $P=(v_0=s, \dots, v_k=v)$ is defined as the sum of the weights of the vertices along the path, excluding the source vertex:
    \[ W'(P) = \sum_{j=1}^{k} w(v_j). \]
    If the path consists only of the source vertex (i.e., $k=0$ and $P=(s)$), its weight is defined as $W'(P)=0$.
\end{definition}


\subsection{Path Weight Aggregation}
\label{subsec:o_set_def}

A key challenge lies in efficiently representing the potentially vast collection of path weights terminating at each vertex. We introduce a set associated with each vertex to capture precisely this information.

\begin{definition}[$\mathcal{O}$-Set]
    \label{def:o_set}
    For each vertex $v \in V$ in a weighted DAG $G=(V, E, w)$ with source $s$, the \emph{$\mathcal{O}$-set}, denoted $\mathcal{O}_v \subseteq \mathbb{N}_0$, is defined recursively. Let us assume a topological ordering of the vertices in $V$. The sets are constructed as follows:
    \begin{itemize}
        \item For the source vertex $v = s$:
              \[ \mathcal{O}_s = \{0\}. \]
        \item For any other vertex $v \neq s$:
              \[ \mathcal{O}_v = \bigcup_{u \in Pred(v)} \{ y + w(v) \mid y \in \mathcal{O}_u \}. \]
    \end{itemize}
\end{definition}
This definition implies that $\mathcal{O}_v$ contains only the distinct values generated by this union process. We consider $\mathcal{O}_v$ to be the set of these unique values, represented as a sorted sequence.


The following proposition establishes the semantic meaning of the $\mathcal{O}$-set, confirming that it correctly captures the set of all possible path weights (as defined in \ref{def:paths_weights}) ending at a vertex.

\begin{proposition}[Semantic Interpretation of $\mathcal{O}$-Set]
    \label{prop:o_set_correctness}
    For any vertex $v \in V$, the set $\mathcal{O}_v$ is precisely the set of cumulative path weights from the source $s$ to $v$:
    \[ \mathcal{O}_v = \{ W'(P) \mid P \in Path(s, v) \}. \]
\end{proposition}
\begin{proof}
    The proof proceeds by induction on the vertices $v \in V$, ordered according to a topological sort of $G$.
    \textit{Base Case:} For the source vertex $v=s$, the only path in $Path(s, s)$ is the trivial path $P=(s)$. According to Definition \ref{def:paths_weights}, $W'(P)=0$. By Definition \ref{def:o_set}, $\mathcal{O}_s = \{0\}$. Thus, the proposition holds for $s$.
    \textit{Inductive Step:} Assume the proposition holds for all vertices $u$ that strictly precede $v$ in the topological order. In particular, this assumption holds for all $u \in Pred(v)$, since the existence of an edge $(u, v)$ implies $u$ precedes $v$ in any topological sort. We must show that $\mathcal{O}_v = \{ W'(P) \mid P \in Path(s, v) \}$.

    ($\subseteq$) Let $x \in \mathcal{O}_v$. By Definition \ref{def:o_set}, since $v \neq s$, there must exist a predecessor $u \in Pred(v)$ and a value $y \in \mathcal{O}_u$ such that $x = y + w(v)$. By the inductive hypothesis applied to $u$, $y = W'(P')$ for some path $P' = (v_0=s, \dots, v_{k-1}=u) \in Path(s, u)$. Consider the path $P = (v_0, \dots, v_{k-1}, v_k=v)$ formed by appending the edge $(u, v)$ to $P'$. This is a valid path in $Path(s, v)$. Its weight according to Definition \ref{def:paths_weights} is
    \begin{align*}
        W'(P) & = \sum_{j=1}^{k} w(v_j) = \left(\sum_{j=1}^{k-1} w(v_j)\right) + w(v_k) \\
              & = W'(P') + w(v) = y + w(v) = x.
    \end{align*}
    Therefore, any element $x \in \mathcal{O}_v$ corresponds to the weight of some path in $Path(s, v)$.

    ($\supseteq$) Let $P = (v_0=s, \dots, v_k=v)$ be an arbitrary path in $Path(s, v)$. Since $v \neq s$, the path must have length $k \ge 1$. Let $u = v_{k-1}$ be the vertex immediately preceding $v$ on this path; thus, $u \in Pred(v)$. Let $P' = (v_0, \dots, v_{k-1})$ be the subpath of $P$ ending at $u$. $P'$ is a path in $Path(s, u)$. By the inductive hypothesis, the weight $W'(P') = \sum_{j=1}^{k-1} w(v_j)$ must be an element of $\mathcal{O}_u$. Let $y = W'(P')$. By Definition \ref{def:o_set}, the value $y + w(v)$ is included in the construction of $\mathcal{O}_v$. We observe that
    \begin{align*}
        y + w(v) & = W'(P') + w(v_k) = \left(\sum_{j=1}^{k-1} w(v_j)\right) + w(v_k) \\
                 & = \sum_{j=1}^{k} w(v_j) = W'(P).
    \end{align*}
    Thus, the weight $W'(P)$ of any path in $Path(s, v)$ is contained in $\mathcal{O}_v$.

    Since both inclusions hold, we conclude that $\mathcal{O}_v = \{ W'(P) \mid P \in Path(s, v) \}$.
\end{proof}

An important property related to the sizes of these $\mathcal{O}$-sets is monotonicity along edges, which plays a role in the design of our succinct structure.

\begin{lemma}[$\mathcal{O}$-Set Cardinality Monotonicity along Edges]
    \label{lem:o_set_cardinality_monotonicity}
    Let $v \in V$ and let $u \in Succ(v)$ be any direct successor of $v$. Then, the cardinality of the $\mathcal{O}$-set of $v$ is less than or equal to the cardinality of the $\mathcal{O}$-set of $u$, i.e., $|\mathcal{O}_v| \le |\mathcal{O}_u|$.
\end{lemma}
\begin{proof}
    From Definition \ref{def:o_set}, the $\mathcal{O}$-set for $u$ is given by
    \[ \mathcal{O}_u = \bigcup_{p \in Pred(u)} \{ y + w(u) \mid y \in \mathcal{O}_p \}. \]
    Since $u$ is a successor of $v$, it follows that $v$ is a predecessor of $u$, i.e., $v \in Pred(u)$. Therefore, the set $S_v = \{ y + w(u) \mid y \in \mathcal{O}_v \}$ contributes to the union forming $\mathcal{O}_u$. Specifically, $S_v \subseteq \bigcup_{p \in Pred(u)} \{ y + w(u) \mid y \in \mathcal{O}_p \}$.
    Consider the mapping $f: \mathcal{O}_v \to S_v$ defined by $f(y) = y + w(u)$. Since $w(u) \ge 0$, this mapping is injective. If $y_1 \neq y_2$, then $y_1 + w(u) \neq y_2 + w(u)$. Consequently, the number of distinct elements in $S_v$ is exactly equal to the number of distinct elements in $\mathcal{O}_v$, so $|S_v| = |\mathcal{O}_v|$.
    The set $\mathcal{O}_u$ is formed by taking the union of sets like $S_v$ for all predecessors $p \in Pred(u)$ and retaining only the unique values. Since the elements generated from $v$'s contribution (namely, $S_v$) are a subset of the elements considered for $\mathcal{O}_u$, the total number of unique elements in $\mathcal{O}_u$ must be at least the number of unique elements contributed by $v$.
    Therefore, $|\mathcal{O}_u| \ge |S_v| = |\mathcal{O}_v|$.
\end{proof}

\begin{figure}[htbp] % htbp suggests placement preference: here, top, bottom, page
    \centering
    \begin{tikzpicture}[
        node distance=1.5cm and 1cm, % Restored original node distance
        base_node/.style={circle, draw=black, thick, minimum size=8mm, inner sep=0pt, font=\sffamily},
        root_node/.style={base_node, fill=red!60, text=black}, % Pastel red fill
        data_label/.style={font=\tiny\sffamily, text=black}, % Restored original data label style
        edge_style/.style={->, >={Stealth[length=2mm]}, thick, draw=black} % Restored original edge style
        ]

        % Nodes: {Weight} Label: {Corrected O-set} - Using original positioning where possible
        \node[root_node, label={[data_label, red, yshift=-0.3cm]below:(0)}] (0) at (0, 2) {0}; % O-set: {0}
        \node[base_node, label={[data_label]below:(1)}] (1) at (1.5, 0) {1}; % O-set: {1}
        \node[base_node, label={[data_label]above:(3)}] (3) at (1.5, 4) {3}; % O-set: {3}
        \node[base_node, label={[data_label]below:(7, 9)}] (6) at (3.5, 1.5) {6}; % O-set: {7, 9}
        \node[base_node, label={[data_label]below:(8)}] (7) at (4.5, 0) {7}; % O-set: {8}
        % Node 2: Using corrected O-set {5, 9, 11} with original label positioning style
        \node[base_node, label={[data_label, xshift=0.3cm]above:(5, 9, 11)}] (2) at (5.5, 4) {2};
        % Node 9: O-set {16, 17, 18}
        \node[base_node, label={[data_label]above:(16, 17, 18)}] (9) at (6.5, 2) {9};
        % Node 5: O-set {13, 21, 22, 23}
        \node[base_node, label={[data_label, xshift=0.3cm]below:(13, 21, 22, 23)}] (5) at (9, 0.5) {5}; % Adjusted X pos slightly vs original for layout
        % Node 10: O-set {15, 19, 21}
        \node[base_node, label={[data_label, xshift=0.3cm]above:(15, 19, 21)}] (10) at (8.5, 5) {10};
        % Node 8: Using corrected O-set {21, 23, ..., 31} with original label positioning style, requires multi-line
        \node[base_node, label={[data_label, align=left]right:(21, 23, 24, 25,\\ 26, 27, 29, 30, 31)}] (8) at (11, 3) {8};

        % Draw Edges (identical to original)
        \draw [edge_style] (0) -- (1);
        \draw [edge_style] (0) -- (3);
        \draw [edge_style] (1) -- (6);
        \draw [edge_style] (1) -- (7);
        \draw [edge_style] (3) -- (2);
        \draw [edge_style] (3) -- (6);
        \draw [edge_style] (6) -- (2);
        \draw [edge_style] (6) -- (9);
        \draw [edge_style] (7) -- (5);
        \draw [edge_style] (7) -- (9);
        \draw [edge_style] (2) -- (10);
        \draw [edge_style] (9) -- (5);
        \draw [edge_style] (9) -- (8);
        \draw [edge_style] (10) -- (8);
        \draw [edge_style] (5) -- (8);

    \end{tikzpicture}
    \caption{Example of a node-weighted DAG. Each node $v$ contains its weight $w(v)$. The label associated with each node represents its calculated $\mathcal{O}$-set, $\mathcal{O}_v$, considered as a sorted sequence.}
    \label{fig:dag_example}
\end{figure}

\begin{example}[$\mathcal{O}$-Set Calculation]
    \label{ex:o_set_calc}
    Consider the weighted DAG shown in \autoref{fig:dag_example}. Each node $v$ is labelled with its weight $w(v)$ inside the circle. The label associated with each node displays its corresponding $\mathcal{O}$-set, calculated according to \ref{def:o_set}. Let us trace the computation for several nodes, respecting a topological order.

    % \begin{itemize}
    %     \item \emph{Node 0 (Source):} $w(0)=0$. By definition, $\mathcal{O}_0 = \{0\}$.
    %     \item \emph{Node 1:} $Pred(1)=\{0\}$, $w(1)=1$.
    %           \[ \mathcal{O}_1 = \{ y + w(1) \mid y \in \mathcal{O}_0 \} = \{ 0 + 1 \} = \{1\}. \]
    %     \item \emph{Node 3:} $Pred(3)=\{0\}$, $w(3)=3$.
    %           \[ \mathcal{O}_3 = \{ y + w(3) \mid y \in \mathcal{O}_0 \} = \{ 0 + 3 \} = \{3\}. \]
    %     \item \emph{Node 6:} $Pred(6)=\{1, 3\}$, $w(6)=6$.
    %           \begin{align*}
    %               \mathcal{O}_6 & = \left( \{ y + w(6) \mid y \in \mathcal{O}_1 \} \right) \cup \left( \{ z + w(6) \mid z \in \mathcal{O}_3 \} \right) \\
    %                             & = \{ 1 + 6 \} \cup \{ 3 + 6 \}                                                                                       \\
    %                             & = \{7\} \cup \{9\} = \{7, 9\}.
    %           \end{align*}
    %     \item \emph{Node 7:} $Pred(7)=\{1\}$, $w(7)=7$.
    %           \[ \mathcal{O}_7 = \{ y + w(7) \mid y \in \mathcal{O}_1 \} = \{ 1 + 7 \} = \{8\}. \]
    %     \item \emph{Node 2:} $Pred(2)=\{3, 6\}$, $w(2)=2$.
    %           \begin{align*}
    %               \mathcal{O}_2 & = \left( \{ y + w(2) \mid y \in \mathcal{O}_3 \} \right) \cup \left( \{ z + w(2) \mid z \in \mathcal{O}_6 \} \right) \\
    %                             & = \{ 3 + 2 \} \cup \{ (7+2), (9+2) \}                                                                                \\
    %                             & = \{5\} \cup \{9, 11\} = \{5, 9, 11\}.
    %           \end{align*}
    %     \item \emph{Node 9:} $Pred(9)=\{6, 7\}$, $w(9)=9$.
    %           \begin{align*}
    %               \mathcal{O}_9 & = \left( \{ y + w(9) \mid y \in \mathcal{O}_6 \} \right) \cup \left( \{ z + w(9) \mid z \in \mathcal{O}_7 \} \right) \\
    %                             & = \{ (7+9), (9+9) \} \cup \{ 8 + 9 \}                                                                                \\
    %                             & = \{16, 18\} \cup \{17\} = \{16, 17, 18\}.
    %           \end{align*}
    %     \item \emph{Node 5:} $Pred(5)=\{7, 9\}$, $w(5)=5$.
    %           \begin{align*}
    %               \mathcal{O}_5 & = \left( \{ y + w(5) \mid y \in \mathcal{O}_7 \} \right) \cup \left( \{ z + w(5) \mid z \in \mathcal{O}_9 \} \right) \\
    %                             & = \{ 8 + 5 \} \cup \{ (16+5), (17+5), (18+5) \}                                                                      \\
    %                             & = \{13\} \cup \{21, 22, 23\} = \{13, 21, 22, 23\}.
    %           \end{align*}
    %     \item \emph{Node 10:} $Pred(10)=\{2\}$, $w(10)=10$. Using $\mathcal{O}_2 = \{5, 9, 11\}$:
    %           \[ \mathcal{O}_{10} = \{ y + w(10) \mid y \in \mathcal{O}_2 \} = \{ (5+10), (9+10), (11+10) \} = \{15, 19, 21\}. \]
    %     \item \emph{Node 8:} $Pred(8)=\{5, 9, 10\}$, $w(8)=8$. Using the previously computed $\mathcal{O}$-sets:
    %           \begin{align*}
    %               \mathcal{O}_8 = & \left( \{ y + w(8) \mid y \in \mathcal{O}_5 \} \right) \cup \left( \{ z + w(8) \mid z \in \mathcal{O}_9 \} \right) \\
    %                               & \cup \left( \{ a + w(8) \mid a \in \mathcal{O}_{10} \} \right)                                                     \\
    %               =               & \{ (13+8), (21+8), (22+8), (23+8) \}                                                                               \\
    %                               & \cup \{ (16+8), (17+8), (18+8) \}                                                                                  \\
    %                               & \cup \{ (15+8), (19+8), (21+8) \}                                                                                  \\
    %               =               & \{ 21, 29, 30, 31 \} \cup \{ 24, 25, 26 \} \cup \{ 23, 27, 29 \}                                                   \\
    %               =               & \{ 21, 23, 24, 25, 26, 27, 29, 30, 31 \} \quad \text{(sorted unique values)}
    %           \end{align*}
    % \end{itemize}
\end{example}

\subsection{The Rank Query}
\label{subsec:rank_dag_def}

Having defined the $\mathcal{O}$-set, which precisely captures the set of all possible cumulative path weights terminating at a given vertex $N$, we now introduce the Rank query. This query builds upon the $\mathcal{O}$-set to provide a richer description related to the path weights.

Intuitively, each value $x \in \mathcal{O}_N$ represents the total accumulated weight along some path from the source $s$ ending exactly at $N$. We can think of the weight $w(N)$ of the node $N$ itself as the contribution or cost associated with the final step or "activity" performed at $N$. The Rank query, $\mathrm{Rank}_G(N)$, aims to capture not just the final cumulative weights $x \in \mathcal{O}_N$, but rather the set of all possible cumulative values that could be considered "active" or relevant \emph{during} the activity represented by node $N$.

Specifically, for a path $P$ reaching $N$ with total weight $W'(P)=x$, the query considers the range of cumulative values from the point just before incorporating $N$'s full weight up to the final value $x$. This corresponds mathematically to the integer interval $[\max(0, x - w(N) + 1), x]$. This interval represents all possible integer cumulative weights observed during the \emph{processing} of node $N$ along that specific path. The Rank query then aggregates these intervals over all possible paths ending at $N$.

This intuition leads to the following formal definition:

\begin{definition}[Rank Query on Weighted DAG]
    \label{def:rank_dag}
    Given a vertex $N \in V$ in a weighted DAG $G=(V, E, w)$, the Rank query, denoted $\mathrm{Rank}_G(N)$, returns a representation of a specific set of integers derived from the $\mathcal{O}$-set $\mathcal{O}_N$. The target set, $S_N \subseteq \mathbb{N}_0$, is defined as the union of intervals generated from each element $x \in \mathcal{O}_N$:
    \[ S_N = \bigcup_{x \in \mathcal{O}_N} \{ z \in \mathbb{N}_0 \mid \max(0, x - w(N) + 1) \le z \le x \}. \]
    The query result is specified as a minimal collection of disjoint, closed integer intervals,
    \[ \mathcal{R}_N = \{[l_1, r_1], [l_2, r_2], \dots, [l_p, r_p]\} \]
    such that their union equals $S_N$,
    \[ \bigcup_{k=1}^{p} [l_k, r_k] = S_N \]
    and the intervals are maximally merged, meaning $r_k < l_{k+1}-1$ for all $k=1, \dots, p-1$
\end{definition}

\begin{remark}
    As motivated above, the transformation from $\mathcal{O}_N$ to the set $S_N$ via the interval generation rule $\{ z \mid \max(0, x - w(N) + 1) \le z \le x \}$ formalizes the idea of capturing the range of values associated with the final node $N$ for each possible incoming path weight $x$. The length of the generated interval is typically $w(N)$ (unless $x < w(N)-1$, in which case it starts from 0), ending precisely at $x$. This mathematical formulation directly implements the intuition of considering values accumulated during the phase associated with node $N$. The subsequent union and merging into disjoint intervals provide a canonical and compact representation of the overall set $S_N$.
\end{remark}

\begin{example}[Rank Query Calculation with Disjoint Result]
    \label{ex:rank_calc_disjoint}
    Let us compute the Rank query for vertex $N=2$ in the DAG shown in \autoref{fig:dag_example}. From Example \ref{ex:o_set_calc}, we have:
    \begin{itemize}
        \item The weight of node 2 is $w(2) = 2$.
        \item The $\mathcal{O}$-set for node 2 is $\mathcal{O}_2 = \{ 5, 9, 11 \}$. These are the possible total weights of paths ending at node 2.
    \end{itemize}
    Applying Definition \ref{def:rank_dag}, we associate an interval with each $x \in \mathcal{O}_2$, representing the values active during the processing of node 2:
    \begin{itemize}
        \item For path weight $x=5$: Interval is $[\max(0, 5 - 2 + 1), 5] = [4, 5]$. These are the values active while accumulating the weight $w(2)=2$ to reach 5.
        \item For path weight $x=9$: Interval is $[\max(0, 9 - 2 + 1), 9] = [8, 9]$.
        \item For path weight $x=11$: Interval is $[\max(0, 11 - 2 + 1), 11] = [10, 11]$.
    \end{itemize}
    The target set $S_2$ is the union of these intervals: $S_2 = [4, 5] \cup [8, 9] \cup [10, 11]$.
    We merge these intervals to obtain the minimal disjoint representation $\mathcal{R}_2$. The intervals are already sorted by starting point.
    \begin{itemize}
        \item Compare $[4, 5]$ and $[8, 9]$. Since $8 > 5 + 1$, they remain separate.
        \item Compare $[8, 9]$ and $[10, 11]$. Since $10 \le 9 + 1$, they are merged into $[8, \max(9, 11)] = [8, 11]$.
    \end{itemize}
    The final minimal collection of disjoint intervals is:
    \[ \mathrm{Rank}_G(2) = \{ [4, 5], [8, 11] \}. \]
    This collection represents the set $S_2 = \{4, 5\} \cup \{8, 9, 10, 11\}$, which encompasses all possible integer cumulative weights that could be considered active during the processing phase associated with node 2, across all possible paths leading to it.
\end{example}

\section{The Succinct DAG Representation}
\label{sec:succinct_dag_representation}

As established, the $\mathcal{O}$-sets can grow significantly in size, rendering their explicit storage for all vertices prohibitive for large graphs. This section details our proposed succinct representation strategy, designed to mitigate this space complexity while still enabling efficient query evaluation. The core idea is to partition the vertices and utilize indirect references guided by a successor relationship.

\subsection*{Successor Selection Heuristic}
\label{subsec:successor_selection}

For an implicit representation of path information, we define a function $\sigma$ that designates a specific successor for each non-sink vertex. This choice is guided by a simple heuristic aimed at minimizing the overall space required for storing the succinct representation.

\begin{definition}[Successor Function $\sigma$]
    \label{def:sigma_function}
    For each vertex $v \in V$ that is not a sink (i.e., $Succ(v) \neq \emptyset$), we select a designated successor $\sigma(v) \in Succ(v)$ according to the following heuristic rule:
    \[ \sigma(v) \in \underset{u \in Succ(v)}{\operatorname{argmin}} \{ |\mathcal{O}_u| \}. \]
\end{definition}
In case of ties (multiple successors minimize the $\mathcal{O}$-set cardinality) we select the successor with the smallest vertex ID among the candidates. The function $\sigma$ is thus well-defined for all non-sink vertices.

\subsection*{Node Partitioning}
\label{subsec:node_partitioning}

The successor function $\sigma$ induces a natural partitioning of the graph's vertices, which dictates how path information is stored or derived for each vertex.

\begin{definition}[Explicit and Implicit Vertices]
    \label{def:explicit_implicit}
    The set of vertices $V$ is partitioned into two disjoint sets:
    \begin{itemize}
        \item $V_E$: The set of \emph{explicit} vertices. This set comprises all sink vertices of the graph $G$:
              \[ V_E = \{ v \in V \mid Succ(v) = \emptyset \}. \]
        \item $V_I$: The set of \emph{implicit} vertices. This set includes all non-sink vertices:
              \[ V_I = V \setminus V_E = \{ v \in V \mid Succ(v) \neq \emptyset \}. \]
    \end{itemize}
\end{definition}
Vertices in $V_E$ serve as base cases in our representation; their associated path weight information ($\mathcal{O}$-sets) is stored directly. For vertices in $V_I$, this information is represented implicitly, relying on references to their designated successor $\sigma(v)$ as defined above.

\subsection{Structure Components}
\label{subsec:structure_components}

We now outline the main components of our data structure designed to represent the weighted DAG $G=(V,E,w)$ succinctly. These components are typically implemented as arrays indexed by vertex ID (from $0$ to $n-1$), enabling a Structure of Arrays (SoA) memory layout \footnote{The SoA organization can be advantageous for cache performance and allows for independent compression strategies for different data types (weights, pointers, path data).}.

\begin{enumerate}
    \item \emph{Weights $\mathcal{W}$:} An array storing the weight $w(v)$ for each vertex $v \in V$., $\mathcal{W}[v] = w(v)$.
    \item \emph{Successor Information $\Sigma$:} An array encoding the successor function $\sigma$ and identifying explicit nodes. For an implicit vertex $v \in V_I$, $\Sigma[v]$ stores the identifier (ID) of its designated successor $\sigma(v)$. For an explicit vertex $v \in V_E$, $\Sigma[v]$ contains a special marker indicating its status.
    \item \emph{Associated Data $\mathcal{D}$:} An array or structure holding the core path weight information, structured differently depending on whether a vertex is explicit or implicit. For a vertex $v$, $\mathcal{D}[v]$ stores either its full $\mathcal{O}$-set (if $v \in V_E$) or an offset sequence $\mathcal{I}_v$ (if $v \in V_I$) that enables reconstruction of $\mathcal{O}_v$ via reference to the data associated with $\sigma(v)$ (and eventually all its successors up to a node in $V_E$).
\end{enumerate}

Let's focus on the content of the Associated Data $\mathcal{D}$ based on the vertex partitioning:

\paragraph{Explicit Vertex Data ($\mathcal{D}_E$)}
For $v \in V_E$ (Explicit Vertex), $\mathcal{D}[v]$ stores the sorted sequence $\mathcal{O}_v$. We denote this stored data representation as $\mathcal{D}_E(v)$. In practice, $\mathcal{D}_E(v)$ would be implemented using a suitable (potentially compressed) representation of the sequence $\mathcal{O}_v$.

\paragraph{Implicit Vertex Data ($\mathcal{D}_I$)}
For $v \in V_I$, let $u = \sigma(v)$ be the designated successor. $\mathcal{D}[v]$ stores the \emph{offset sequence} $\mathcal{I}_v$. This sequence $\mathcal{I}_v = (j_0, j_1, \dots, j_{m-1})$ is a strictly monotonically increasing sequence of $m = |\mathcal{O}_v|$ indices. The index $j_k$ (stored at position $k$ in $\mathcal{I}_v$) indicates that the $k$-th element of $\mathcal{O}_v$ (let it be $x_k$) can be computed from the $j_k$-th element of $\mathcal{O}_u$ (let it be $y_{j_k}$) using the reconstruction rule: $x_k = y_{j_k} - w(u)$. We denote this stored sequence representation as $\mathcal{D}_I(v)$.

The successor information $\Sigma[v]$ provides the link $u = \sigma(v)$, and the weight $w(u)$ needed for the reconstruction is retrieved from $\mathcal{W}[u]$.

\begin{proposition}
    \label{prop:o_set_size_guarantee}
    For any implicit node $v \in V_I$, let $u = \sigma(v)$ be its designated successor chosen according to Definition \ref{def:sigma_function}. Then $|\mathcal{O}_v| \le |\mathcal{O}_u|$.
\end{proposition}
\begin{proof}
    This is a direct consequence of Lemma \ref{lem:o_set_cardinality_monotonicity}. Since $\sigma(v)$ is chosen from the set $Succ(v)$ of direct successors of $v$, the lemma applies, yielding $|\mathcal{O}_v| \le |\mathcal{O}_{\sigma(v)}|$.
\end{proof}
This inequality guarantees that the length of the offset sequence $\mathcal{I}_v$ (which is $m = |\mathcal{O}_v|$) is no greater than the length of the sequence $\mathcal{O}_u$ (which is $|\mathcal{O}_u|$) from which values are derived. Furthermore, the reconstruction rule $x_k = y_{j_k} - w(u)$ implies that each $x_k \in \mathcal{O}_v$ originates from some element in $\mathcal{O}_u$ (shifted by $-w(u)$). The offset sequence $\mathcal{I}_v$ stores the index $j_k$ in $\mathcal{O}_u$ corresponding to the $k$-th element $x_k$ in $\mathcal{O}_v$.

The heuristic choice of $\sigma(v)$ (\ref{def:sigma_function}) aims to minimize $|\mathcal{O}_{\sigma(v)}|$. While this is a greedy, local optimization, the intuition is that choosing a successor with a smaller $\mathcal{O}$-set might lead to offset sequences $\mathcal{I}_v$ that are structurally simpler or involve smaller index values, potentially improving the compressibility of the $\mathcal{D}_I(v)$ component.

\begin{remark}[Unique Sink Transformation]
    If the DAG $G=(V, E, w)$ possesses multiple sink vertices ($v$ with $Succ(v) = \emptyset$), we can decide to transform it to have a unique sink. This is achieved by introducing a virtual sink vertex $t'$ with $w(t') = 0$, setting $V' = V \cup \{t'\}$, and defining the edge set $E' = E \cup \{ (v, t') \mid v \in V \text{ and } Succ_G(v) = \emptyset \}$. In the resulting graph $G'=(V', E', w')$, $t'$ becomes the unique sink.

    This transformation preserves the $\mathcal{O}$-sets for all original vertices $v \in V$. Its primary benefit for our representation is structural: the set of explicit vertices $V_E$ (Definition \ref{def:explicit_implicit}) reduces to the singleton $\{t'\}$. This potentially decreases the storage needed for the explicit data component $\mathcal{D}_E$, as only $\mathcal{O}_{t'}$ (which aggregates path information from all original sinks) needs explicit storage. Therefore, when discussing the representation structure, we may assume, without loss of generality, that such a transformation has been applied if beneficial, resulting in a unique sink.
\end{remark}


\subsection*{Example of the Structure}
\label{subsec:structure_example}

To concretely illustrate the succinct representation, let us apply the principles from \autoref{subsec:structure_components} to the example DAG introduced in \autoref{fig:dag_example}. The resulting structure is visualized in \autoref{fig:succinct_dag_example}.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=1.5cm and 1cm, % Restored original node distance
        base_node/.style={circle, draw=black, thick, minimum size=8mm, inner sep=0pt, font=\sffamily},
        root_node/.style={base_node, fill=red!60, text=black}, % Pastel red fill
        implicit_node/.style={base_node}, % Standard style for implicit nodes
        explicit_node/.style={base_node, fill=green!40, text=black}, % Style for explicit nodes
        data_label/.style={font=\tiny\sffamily\bfseries, text=blue!70!black, inner sep=1pt}, % Adjusted data label style slightly
        edge_style/.style={->, >={Stealth[length=2mm]}, thick, draw=black!30}, % Normal edges faint
        successor_edge/.style={->, >={Stealth[length=2mm, width=1.5mm]}, very thick, draw=blue!65} % Highlighted successor edge
        ]

        % Nodes with weights and associated data (Offset I or O-set O)
        \node[root_node, label={[data_label, red!80!black, yshift=-0.3cm]below:{$\mathcal{I}_0=(0)$}}] (0) at (0, 2) {0};
        \node[implicit_node, label={[data_label, yshift=-0.3cm]below:{$\mathcal{I}_1=(0)$}}] (1) at (1.5, 0) {1};
        \node[implicit_node, label={[data_label, yshift=0.2cm]above:{$\mathcal{I}_3=(1)$}}] (3) at (1.5, 4) {3};
        \node[implicit_node, label={[data_label, xshift=-0.5cm, yshift=-0.3cm]below right:{$\mathcal{I}_6=(1, 2)$}}] (6) at (3.5, 1.5) {6};
        \node[implicit_node, label={[data_label, yshift=-0.3cm]below:{$\mathcal{I}_7=(1)$}}] (7) at (4.5, 0) {7};
        \node[implicit_node, label={[data_label, xshift=-0.8cm, yshift=0.2cm]above right:{$\mathcal{I}_2=(0, 1, 2)$}}] (2) at (5.5, 4) {2};
        \node[implicit_node, label={[data_label, yshift=0.2cm]above:{$\mathcal{I}_9=(1, 2, 3)$}}] (9) at (6.5, 2) {9};
        \node[explicit_node, label={[data_label, align=left, xshift=0.4cm]right:{$\mathcal{O}_8=\{21, 23, 24, 25,$ \\ $26, 27, 29, 30, 31\}$}}] (8) at (11.5, 3) {8};
        \node[implicit_node, label={[data_label, xshift=-0.5cm, yshift=-0.3cm]below right:{$\mathcal{I}_5=(0, 6, 7, 8)$}}] (5) at (9, 0.5) {5};
        \node[implicit_node, label={[data_label, xshift=-0.9cm, yshift=0.2cm]above right:{$\mathcal{I}_{10}=(1, 5, 6)$}}] (10) at (8.5, 5) {10};

        % Faint original edges
        \draw [edge_style] (0) -- (1); \draw [edge_style] (0) -- (3);
        \draw [edge_style] (1) -- (6); \draw [edge_style] (1) -- (7);
        \draw [edge_style] (3) -- (2); \draw [edge_style] (3) -- (6);
        \draw [edge_style] (6) -- (2); \draw [edge_style] (6) -- (9);
        \draw [edge_style] (7) -- (5); \draw [edge_style] (7) -- (9);
        \draw [edge_style] (2) -- (10);
        \draw [edge_style] (9) -- (5); \draw [edge_style] (9) -- (8);
        \draw [edge_style] (10) -- (8);
        \draw [edge_style] (5) -- (8);

        % Highlighted successor edges (sigma function)
        % Assume heuristic choices based on O-set sizes from Fig 1 example:
        % sigma(0): Succ={1,3}. |O1|=1, |O3|=1. Tie-break: min ID -> sigma(0)=1
        % sigma(1): Succ={6,7}. |O6|=2, |O7|=1. -> sigma(1)=7
        % sigma(3): Succ={2,6}. |O2|=3, |O6|=2. -> sigma(3)=6
        % sigma(6): Succ={2,9}. |O2|=3, |O9|=3. Tie-break: min ID -> sigma(6)=2
        % sigma(7): Succ={5,9}. |O5|=4, |O9|=3. -> sigma(7)=9
        % sigma(2): Succ={10}. |O10|=3. -> sigma(2)=10
        % sigma(9): Succ={5,8}. |O5|=4, |O8|=9. -> sigma(9)=5
        % sigma(10): Succ={8}. |O8|=9. -> sigma(10)=8
        % sigma(5): Succ={8}. |O8|=9. -> sigma(5)=8
        \draw [successor_edge] (0) -- (1); % sigma(0)=1
        \draw [successor_edge] (1) -- (7); % sigma(1)=7
        \draw [successor_edge] (3) -- (6); % sigma(3)=6
        \draw [successor_edge] (6) -- (2); % sigma(6)=2 (Corrected from original text example; assuming tie-break by ID)
        \draw [successor_edge] (7) -- (9); % sigma(7)=9
        \draw [successor_edge] (2) -- (10); % sigma(2)=10
        \draw [successor_edge] (9) -- (5); % sigma(9)=5
        \draw [successor_edge] (5) -- (8); % sigma(5)=8
        \draw [successor_edge] (10) -- (8); % sigma(10)=8

    \end{tikzpicture}
    \caption{Illustration of the succinct DAG representation for the graph in \autoref{fig:dag_example}. Implicit nodes are shown with standard borders, while the explicit sink node (8) is shaded green. The source node (0) is red. Highlighted blue edges indicate the chosen successor $\sigma(v)$ for each implicit node $v$, selected according to Definition \ref{def:sigma_function}. Labels show the stored associated data $\mathcal{D}[v]$: the full $\mathcal{O}$-set for the explicit node 8, and the offset sequence $\mathcal{I}_v$ for all implicit nodes.}
    \label{fig:succinct_dag_example}
\end{figure}

The construction proceeds in three main steps:

\begin{enumerate}
    \item \emph{Partitioning:} Vertices are partitioned into explicit sinks $V_E = \{ v \mid Succ(v) = \emptyset \}$ and implicit non-sinks $V_I = V \setminus V_E$. In the example (\autoref{fig:succinct_dag_example}), $V_E=\{8\}$.

    \item \emph{Successor Selection:} For each $v \in V_I$, a successor $\sigma(v)$ is chosen from $Succ(v)$ to minimize $|\mathcal{O}_{\sigma(v)}|$. The selected successors are shown as blue edges in \autoref{fig:succinct_dag_example}. For example, $\sigma(0)=1$, $\sigma(1)=7$, $\sigma(3)=6$, etc.
    \item \emph{Associated Data Determination:} The data $\mathcal{D}[v]$ depends on the vertex type:
          For $v \in V_E$, the full $\mathcal{O}$-set is stored: $\mathcal{D}[v] = \mathcal{D}_E(v) = \mathcal{O}_v$. E.g., $\mathcal{D}[8] = \mathcal{O}_8$ in the figure.

          For $v \in V_I$, the offset sequence $\mathcal{I}_v$ is stored: $\mathcal{D}[v] = \mathcal{D}_I(v) = \mathcal{I}_v$. Let $u = \sigma(v)$. The sequence $\mathcal{I}_v = (j_0, \dots, j_{m-1})$ where $m=|\mathcal{O}_v|$, provides the indices $j_k$ such that the $k$-th element $x_k$ of $\mathcal{O}_v$ is reconstructed from the $j_k$-th element $y_{j_k}$ of $\mathcal{O}_u$ via the rule $x_k = y_{j_k} - w(u)$.

          For example, consider $v=3$. We have $\sigma(3)=6$, $w(6)=6$, $\mathcal{O}_3=\{3\}$ (so $x_0=3$), and $\mathcal{O}_6=\{7, 9\}$ (so $y_0=7, y_1=9$). We need $j_0$ such that $x_0 = y_{j_0} - w(6)$, i.e., $3 = y_{j_0} - 6$. This gives $y_{j_0}=9$, which corresponds to index $j_0=1$ in $\mathcal{O}_6$. Thus, $\mathcal{I}_3 = (1)$.

          The offset sequences for all implicit nodes are computed similarly and displayed as labels in \autoref{fig:succinct_dag_example}.
\end{enumerate}

This structure stores $\mathcal{O}$-sets only for sinks, relying on successor paths and offset sequences for implicit nodes, enabling query evaluation via traversal as shown in \autoref{fig:query_path_node7}.

This representation avoids storing the full $\mathcal{O}$-sets for implicit nodes. Instead, it stores references (via $\sigma$) and transformations (via $\mathcal{I}_v$ and weights $\mathcal{W}$). Queries for implicit nodes require traversing the successor path until an explicit node is reached, as illustrated next.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=1.6cm and 1.1cm, % Base distance, actual positions set via coordinates
        base_node/.style={circle, draw=black, thick, minimum size=9mm, inner sep=0pt, font=\sffamily},
        implicit_node/.style={base_node},
        explicit_node/.style={base_node, fill=green!40, text=black},
        % Define specific label styles for reuse
        node_label_above/.style={font=\tiny\sffamily\bfseries, text=blue!70!black, inner sep=1pt, align=center, above, yshift=1mm},
        node_label_below/.style={font=\tiny\sffamily\bfseries, text=blue!70!black, inner sep=1pt, align=center, below, yshift=-2mm},
        node_label_inside/.style={font=\tiny\sffamily\bfseries, text=blue!70!black, inner sep=0pt, align=center}, % Changed color to match others
        % Edge labels
        step_label/.style={font=\sffamily\scriptsize, text=black, above, midway, sloped, yshift=1mm, inner sep=1pt}, % Added inner sep
        weight_label/.style={font=\sffamily\scriptsize, text=red!80!black, below, midway, sloped, yshift=-1mm, inner sep=1pt}, % Added inner sep
        annotation/.style={font=\sffamily\tiny, text=black, align=center}, % Consistent annotation style
        result_label/.style={font=\sffamily\scriptsize\bfseries, text=purple!80},
        successor_edge/.style={->, >={Stealth[length=2mm, width=1.5mm]}, very thick, draw=blue!65} % Pastel blue
        ]

        % Nodes involved in the query path with adjusted coordinates and labels to match the image
        \node[implicit_node, label={[node_label_inside]:{$\mathcal{I}_7=(1)$}}] (N7) at (0,0) {7};
        \node[implicit_node, label={[node_label_above]:{$\mathcal{I}_9=(1, 2, 3)$}}] (N9) at (3,1.5) {9};
        \node[implicit_node, label={[node_label_below, yshift=-8mm]:{$\mathcal{I}_5=(0, 6, 7, 8)$}}] (N5) at (5.5,-0.5) {5};
        \node[explicit_node, label={[node_label_above]:{$\mathcal{O}_8=\{21, 23, 24, 25,$ \\ $26, 27, 29, 30, 31\}$}}] (N8) at (8.5,1.5) {8};

        % % Annotations adjusted based on new node positions to match the image layout
        \node[annotation, anchor=south] at ([yshift=-0.5cm]N7.south) {index $k=0$, $sum=0$};
        \node[annotation, anchor=north] at ([yshift=0.8cm]N9.north) {index $k=1$, $sum=9$};
        \node[annotation, anchor=south] at ([yshift=-0.8cm]N5.south) {index $k=2$, $sum=14$};
        \node[annotation, anchor=east] at ([xshift=1.6cm, yshift=-0.7cm]N8.east) {index $k=7$, $sum=22$};

        % Successor Edges for the path with sloped labels
        \draw [successor_edge] (N7) -- node[step_label] {Use $\mathcal{I}_7[0]=\mathbf{1}$}
        node[weight_label] {$+ w(9)=9$} (N9);
        \draw [successor_edge] (N9) -- node[step_label] {Use $\mathcal{I}_9[1]=\mathbf{2}$}
        node[weight_label] {$+ w(5)=5$} (N5);
        \draw [successor_edge] (N5) -- node[step_label] {Use $\mathcal{I}_5[2]=\mathbf{7}$}
        node[weight_label] {$+ w(8)=8$} (N8);

        \node[annotation, below=1.1cm of N8, xshift=0.4cm] (Calc) {Retrieve $\mathcal{O}_8[7] = 30$. \\ Final Result = $30 - sum = 30 - 22 = \mathbf{8}$.}; % Slightly adjusted vertical position
        \node[result_label, below=0.1cm of Calc] {Result: $\mathcal{O}_7[0] = 8$};

    \end{tikzpicture}
    \caption{Visualization of the query process for retrieving the element at index $k=0$ of $\mathcal{O}_7$ using the succinct representation. The query follows the successor path $7 \to 9 \to 5 \to 8$. At each step from an implicit node $v$ to its successor $u=\sigma(v)$, the current index $k_{current}$ is updated using the stored offset $k_{next} = \mathcal{I}_v[k_{current}]$, and the weight $w(u)$ is added to an accumulator. The path starts with $k=0$ at node 7. It proceeds to node 9 using index $\mathcal{I}_7[0]=1$, accumulating $w(9)=9$. Then to node 5 using index $\mathcal{I}_9[1]=2$, accumulating $w(5)=5$ (total sum 14). Then to node 8 using index $\mathcal{I}_5[2]=7$, accumulating $w(8)=8$ (total sum 22). Node 8 is explicit, so the value at the final index 7, $\mathcal{O}_8[7]=30$, is retrieved. The result is obtained by subtracting the total accumulated weight: $30 - 22 = 8$. This correctly reconstructs $\mathcal{O}_7[0]$.}
    \label{fig:query_path_node7} % Keep the same label if it replaces the previous figure
\end{figure}

The example in \autoref{fig:query_path_node7} illustrates how a specific value from an implicit node's $\mathcal{O}$-set can be reconstructed. The query for $\mathcal{O}_7[0]$ triggers a traversal along the $\sigma$-defined path $7 \to 9 \to 5 \to 8$. During this traversal, the offset sequences ($\mathcal{I}_7, \mathcal{I}_9, \mathcal{I}_5$) are used to update the target index within the respective successor's $\mathcal{O}$-set representation, and the weights of the successors ($w(9), w(5), w(8)$) are accumulated. Once the explicit node (8) is reached, the value at the final computed index (7) is retrieved from the stored $\mathcal{O}_8$. Subtracting the accumulated weight sum (22) from this base value (30) yields the desired result (8).

\section{Query Algorithms}
\label{sec:query_algorithms}

This section details the algorithms operating on the succinct DAG representation introduced in \autoref{sec:succinct_dag_representation}. We first present the algorithm for reconstructing elements of the $\mathcal{O}$-set for any given vertex, which forms the basis for computing the Rank query.

\subsection{Reconstructing $\mathcal{O}$-Sets}
\label{subsec:reconstructing_o_sets}

The core operation is to determine the value of the $k$-th element (0-indexed) of $\mathcal{O}_v$ for an arbitrary vertex $v$. If $v$ is explicit ($v \in V_E$), this involves directly accessing the stored representation $\mathcal{D}_E(v)$. If $v$ is implicit ($v \in V_I$), the value must be reconstructed by traversing the successor path defined by $\sigma$ until an explicit vertex is reached, accumulating weights and applying the offset indices stored in the $\mathcal{I}$ sequences along the path.

We define the function $\textsc{GetValue}(v, k)$ to perform this task. It relies on accessing the structure components: weights $\mathcal{W}$, successor information $\Sigma$ (to get $\sigma(v)$ and check for explicit nodes), and associated data $\mathcal{D}$ (to retrieve $\mathcal{I}$ sequences or $\mathcal{O}$-sets).

\begin{algorithm}
    \caption{$\textsc{GetValue}(v, k)$: Compute the $k$-th element of $\mathcal{O}_v$}
    \label{alg:get_value}
    \small
    \begin{algorithmic}[1]
        \Require Vertex ID $v$, index $k \in \{0, \dots, |\mathcal{O}_v|-1\}$.
        \Ensure The value of the $k$-th smallest element in $\mathcal{O}_v$.
        \State $current\_node \gets v$
        \State $current\_index \gets k$
        \State $weight\_sum \gets 0$
        \While{$current\_node \notin V_E$}
        \State $successor \gets \sigma(current\_node)$
        \State $weight\_sum \gets weight\_sum + \mathcal{W}[successor]$
        \State $\mathcal{I}_{current\_node} \gets \mathcal{D}_I(current\_node)$
        \State $next\_index \gets \mathcal{I}_{current\_node}[current\_index]$
        \State $current\_node \gets successor$
        \State $current\_index \gets next\_index$
        \EndWhile

        \State $\mathcal{O}_{explicit} \gets \mathcal{D}_E(current\_node)$
        \State $base\_value \gets \mathcal{O}_{explicit}[current\_index]$
        \State \Return $base\_value - weight\_sum$
    \end{algorithmic}
\end{algorithm}

The correctness of Algorithm \ref{alg:get_value} follows inductively from the definition of the offset sequence $\mathcal{I}_v$. Let $x_k^{(v)}$ denote the $k$-th element of $\mathcal{O}_v$. If $v$ is implicit with successor $u = \sigma(v)$, then by construction $x_k^{(v)} = x_{j_k}^{(u)} - w(u)$, where $j_k = \mathcal{I}_v[k]$. The algorithm iteratively applies this relation: if $v \to u \to \dots \to e$ is the successor path ending at an explicit node $e$, and the indices transform as
\[ k \to j_k^{(v)} \to j_{j_k^{(v)}}^{(u)} \to \dots \to K \]
then the algorithm computes
\[x_K^{(e)} - \sum_{z \in \text{path } v \to e, z \neq v} w(z)\]
which correctly yields $x_k^{(v)}$. The visualization in \autoref{fig:query_path_node7} provides a concrete example of this process.

To reconstruct the entire $\mathcal{O}$-set for a vertex $v$, we can repeatedly call $\textsc{GetValue}(v, k)$ for $k=0, 1, \dots, |\mathcal{O}_v|-1$. This requires knowing the size $|\mathcal{O}_v|$. We assume this size information is either stored explicitly for each node or can be efficiently derived (e.g., potentially stored alongside $\mathcal{I}_v$ or $\mathcal{O}_v$ in the $\mathcal{D}$ component). Let $\textsc{Length}(v)$ be an operation that returns $|\mathcal{O}_v|$.

\begin{algorithm}
    \caption{$\textsc{GetOSet}(v)$: Reconstruct the $\mathcal{O}$-set for vertex $v$}
    \label{alg:get_o_set}
    \small
    \begin{algorithmic}[1]
        \Require Vertex ID $v$.
        \Ensure The sorted sequence $\mathcal{O}_v$.
        \State $size \gets \textsc{Length}(v)$ \Comment{Obtain the cardinality of $\mathcal{O}_v$}
        \State Initialize an empty list $O\_list$ of size $size$.
        \For{$k$ from $0$ to $size - 1$}
        \State $value \gets \textsc{GetValue}(v, k)$ \Comment{Compute the $k$-th element}
        \State $O\_list[k] \gets value$ \Comment{Store in list}
        \EndFor
        \State \Return $O\_list$ \Comment{The list contains $\mathcal{O}_v$ as a sorted sequence}
    \end{algorithmic}
\end{algorithm}

\subsection{Computing the Rank Query}
\label{subsec:computing_rank}

Equipped with the capability to reconstruct $\mathcal{O}_N$ for any query vertex $N$ via Algorithm \ref{alg:get_o_set}, we can now implement the Rank query as specified in \ref{def:rank_dag}. The procedure involves two main steps: first, generate the initial set of intervals based on the elements of $\mathcal{O}_N$ and the weight $w(N)$; second, merge these potentially overlapping or adjacent intervals into a minimal set of disjoint intervals.

The interval merging step is a standard procedure. Given a list of intervals sorted by their starting points, we can merge them in linear time. Algorithm \ref{alg:merge_intervals} describes this process.
\begin{algorithm}[htbp]
    \caption{$\textsc{MergeIntervals}(Intervals)$: Merge sorted intervals}
    \label{alg:merge_intervals}
    \small
    \begin{algorithmic}[1]
        \Require A list $Intervals = \{[l_1, r_1], [l_2, r_2], \dots\}$ sorted by start points $l_i$.
        \Ensure A minimal list $MergedIntervals$ of disjoint intervals covering the same union.
        \State Initialize an empty list $MergedIntervals$.
        \If{$Intervals$ is not empty}
        \State $current\_interval \gets Intervals[0]$.
        \For{$i$ from $1$ to length$(Intervals) - 1$}
        \State $next\_interval \gets Intervals[i]$.
        \If{$next\_interval.l \le current\_interval.r + 1$}
        \State $current\_interval.r \gets \max(current\_interval.r, next\_interval.r)$
        \Else
        \State Append $current\_interval$ to $MergedIntervals$.
        \State $current\_interval \gets next\_interval$.
        \EndIf
        \EndFor
        \State Append $current\_interval$ to $MergedIntervals$.
        \EndIf
        \State \Return $MergedIntervals$.
    \end{algorithmic}
\end{algorithm}

The overall Rank query algorithm combines $\mathcal{O}$-set reconstruction and interval merging.

\begin{algorithm}
    \caption{$\mathrm{Rank}_G(N)$: Compute the Rank query for vertex $N$}
    \label{alg:rank_dag}
    \small
    \begin{algorithmic}[1]
        \Require Vertex ID $N$.
        \Ensure A minimal set of disjoint intervals $\mathcal{R}_N$ representing $S_N$
        \State $\mathcal{O}_N \gets \textsc{GetOSet}(N)$
        \State $w_N \gets \mathcal{W}[N]$
        \State Initialize an empty list $InitialIntervals$.
        \For{each $x \in \mathcal{O}_N$}
        \State $l \gets \max(0, x - w_N + 1)$
        \State $r \gets x$
        \State Append the interval $[l, r]$ to $InitialIntervals$.
        \EndFor
        \State Sort $InitialIntervals$ based on the starting point $l$.
        \State $MergedIntervals \gets \textsc{MergeIntervals}(InitialIntervals)$
        \State \Return $MergedIntervals$.
    \end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:rank_dag} implements the Rank query defined in \ref{def:rank_dag}. It first reconstructs the necessary path weight information ($\mathcal{O}_N$), then applies the specified transformation to generate the initial set of intervals
\[S_N = \bigcup_{x \in \mathcal{O}_N} [ \max(0, x - w_N + 1), x ]\]
Finally, it employs the standard interval merging algorithm to produce the canonical representation $\mathcal{R}_N$ as a minimal set of disjoint intervals. Note that the sorting step (line 9) is necessary because intervals generated from consecutive elements in $\mathcal{O}_N$ are not guaranteed to have non-decreasing start points.

\subsubsection*{Example: Rank Query Computation \label{subsubsec:rank_query_example_node2}}

Let's trace the execution of Algorithm \ref{alg:rank_dag} to compute $\mathrm{Rank}_G(N)$ for the only node with weight $2$, in the representation already shown in \autoref{fig:dag_example} and \autoref{fig:succinct_dag_example}.

First, the algorithm requires the $\mathcal{O}$-set for node 2. It calls $\textsc{GetOSet}(2)$ (Algorithm \ref{alg:get_o_set}), which in turn relies on $\textsc{GetValue}(2, k)$ (Algorithm \ref{alg:get_value}) for $k=0, 1, \dots, |\mathcal{O}_2|-1$. $\textsc{GetValue}$ traverses the successor path determined by $\sigma$. For node 2, the successor path is $2 \to 10 \to 8$. Following this path, applying the stored offset indices $\mathcal{I}_2, \mathcal{I}_{10}$, accumulating weights $w(10)$ and $w(8)$, and finally retrieving the base value from the explicit node $\mathcal{O}_8$, yields the set $\mathcal{O}_2 = \{5, 9, 11\}$.

Next, the weight of the query node is retrieved: $w_N = w(2) = 2$.

The algorithm then proceeds to generate the initial set of intervals. Each element $x$ from $\mathcal{O}_2$ maps to an interval $[\max(0, x - w_2 + 1), x]$:
\begin{align*}
    x=5 \quad  & \longrightarrow \quad [\max(0, 5 - 2 + 1), 5] = [4, 5]     \\
    x=9 \quad  & \longrightarrow \quad [\max(0, 9 - 2 + 1), 9] = [8, 9]     \\
    x=11 \quad & \longrightarrow \quad [\max(0, 11 - 2 + 1), 11] = [10, 11]
\end{align*}
This yields the initial list $Intervals = \{ [4, 5], [8, 9], [10, 11] \}$.

Finally, $\textsc{MergeIntervals}$ (\ref{alg:merge_intervals}) is applied to this sorted list. The intervals $[8, 9]$ and $[10, 11]$ merge into $[8, 11]$. The interval $[4, 5]$ remains separate. The final result returned by $\mathrm{Rank}_G(2)$ is the minimal set of disjoint intervals $\mathcal{R}_2 = \{ [4, 5], [8, 11] \}$.

\section{Compression Strategies}
\label{sec:compression_strategies}

The succinct representation detailed in \autoref{sec:succinct_dag_representation} comprises three main components: the weights array $\mathcal{W}$, the successor information array $\Sigma$, and the associated data array $\mathcal{D}$. While the partitioning strategy itself reduces the need to store large $\mathcal{O}$-sets explicitly for all nodes, the components $\mathcal{W}$, $\Sigma$, and especially $\mathcal{D}$ can still consume significant space. This section explores strategies for further compressing these components, leveraging the techniques discussed in \autoref{ch:Chapter2} and \autoref{ch:Chapter3}, as well as the implementation concepts from \autoref{app:compressed_intvec_engineering}. Our goal is to minimize the space occupancy while maintaining efficient query performance, particularly for the reconstruction step (\autoref{alg:get_value}) underlying the Rank query (\autoref{alg:rank_dag}).

\subsection{Compressing Weights and Successor Information}
\label{subsec:compressing_W_Sigma}

The components $\mathcal{W}$ and $\Sigma$ are arrays of integers.
\begin{itemize}
    \item $\mathcal{W}$: An array of length $n = |V|$, where $\mathcal{W}[v] = w(v) \in \mathbb{N}_0$. The values are non-negative integers representing vertex weights, without any guarantee of monotonicity or specific distribution patterns a priori.
    \item $\Sigma$: An array of length $n$, where $\Sigma[v]$ stores either the integer ID $\sigma(v) \in \{0, \dots, n-1\}$ if $v \in V_I$, or a special marker (which can also be represented as an integer) if $v \in V_E$. This is also fundamentally a sequence of integers.
\end{itemize}

Given that both $\mathcal{W}$ and $\Sigma$ are sequences of integers, the variable-length integer coding schemes discussed in \autoref{sec:integer_coding} are natural candidates for compression. Techniques such as Unary, Elias Gamma/Delta, or Rice codes can be employed. The optimal choice depends heavily on the empirical distribution of the weights $w(v)$ and the successor IDs $\sigma(v)$ (and the chosen marker value) within the specific DAG instance. For example, if weights are typically small, Gamma or Delta codes might be effective. If successor IDs cluster or follow certain patterns, other codes might be preferable.

A practical approach to implement this compression while preserving the necessary random access capability (i.e., efficiently retrieving $\mathcal{W}[v]$ or $\Sigma[v]$ for any $v$) is provided by the engineered \textsf{compressed-intvec} structure described in \autoref{app:compressed_intvec_engineering}. This structure allows selecting an appropriate integer codec (e.g., Gamma, Delta, Rice) based on the data distribution and employs a sampling mechanism to ensure $O(1)$ expected time access to any element $v$, at the cost of a typically sub-linear space overhead for the samples.

Alternatively, if the range of possible integer values in $\mathcal{W}$ or $\Sigma$ (i.e., the maximum weight or $n$) is sufficiently small to be considered a small alphabet $\alpha$, one could choose to use Wavelet Trees (\autoref{sec:wavelet_trees}), particularly efficient variants like Wavelet Matrices or Quad Wavelet Trees (\autoref{sec:wavelet_matrices_and_quad_vectors}). These structures provide efficient Access (retrieving the element at a given position) in $O(\log \alpha)$ time, where $\alpha$ is the size of the alphabet (the number of distinct values). However, for general graphs where weights or vertex counts $n$ can be large, the alphabet size may not be small, making direct integer coding via \textsf{compressed-intvec} a more generally applicable starting point.

\subsection{Compressing Associated Data Sequences}
\label{subsec:compressing_associated_data_sequences}

The associated data component $\mathcal{D}$ holds the core path weight information, represented as sequences tied to each vertex. For an explicit vertex $v \in V_E$, $\mathcal{D}$ contains the $\mathcal{O}$-set $\mathcal{O}_v = (x_0, x_1, \dots, x_{m-1})$, where $m = |\mathcal{O}_v|$. This sequence consists of non-negative integers and, by Definition \ref{def:o_set}, is strictly increasing ($0 \le x_0 < x_1 < \dots < x_{m-1}$).
For an implicit vertex $v \in V_I$, $\mathcal{D}$ contains the offset sequence $\mathcal{I}_v = (j_0, j_1, \dots, j_{m-1})$, where $m = |\mathcal{O}_v|$. As established by the reconstruction rule $x_k = y_{j_k} - w(u)$ and the fact that $\mathcal{O}_v$ and $\mathcal{O}_u$ (where $u=\sigma(v)$) are themselves strictly increasing sequences, the offset sequence $\mathcal{I}_v$ is also strictly increasing ($0 \le j_0 < j_1 < \dots < j_{m-1}$).

The strictly monotonic nature of both $\mathcal{O}_v$ and $\mathcal{I}_v$ makes them highly suitable for compression methods designed for such sequences. Elias-Fano encoding (\autoref{sec:elias_fano_code}), already discussed, provides excellent compression guarantees and support for efficient random access and predecessor/successor queries.

Alternatively, especially if sequences exhibit significant clustering (long stretches of consecutive integers), Run-Length Encoding (RLE) can offer substantial compression. We focus here on describing the RLE approach as applied to these strictly monotonic sequences.

\subsubsection*{Run-Length Encoding (RLE) Representation}

Run-Length Encoding exploits consecutive values within a monotonic sequence. Consider a generic strictly increasing sequence $Y = (y_0, y_1, \dots, y_{m-1})$. A \emph{run} is defined as a maximal contiguous subsequence of the form $(y_i, y_{i+1}, \dots, y_{i+l-1})$ such that $y_{j+1} = y_j + 1$ for all $j$ where $i \le j < i+l-1$. Note that a run can have length $l=1$ if an element does not have a consecutive successor in the sequence. The RLE approach encodes $Y$ by representing each run by its starting value and its length.

Formally, the RLE of $Y$ generates two sequences:
\begin{itemize}
    \item The \emph{run starts sequence}, $S = (s_1, s_2, \dots, s_p)$, where $s_i$ is the first value ($y_{i'}$) of the $i$-th run identified in $Y$. Due to the maximality of runs and the strict monotonicity of $Y$, $S$ is also a strictly increasing sequence: $s_1 < s_2 < \dots < s_p$.
    \item The \emph{run lengths sequence}, $L = (l_1, l_2, \dots, l_p)$, where $l_i \ge 1$ is the number of elements (length) of the $i$-th run. $L$ is a sequence of positive integers, possessing no inherent monotonicity property.
\end{itemize}
The pair $(S, L)$ uniquely determines the original sequence $Y$. Algorithm \ref{alg:rle_encode} provides the procedure for generating $S$ and $L$.

\begin{algorithm}[htbp]
    \caption{$\textsc{EncodeRLE}(Y)$: Generate RLE components for a monotonic sequence}
    \label{alg:rle_encode} % Changed label to avoid duplicate
    \small
    \begin{algorithmic}[1]
        \Require Monotonic sequence $Y = (y_0, y_1, \dots, y_{m-1})$, where $m = |Y|$.
        \Ensure Run starts sequence $S$, Run lengths sequence $L$.
        \State Initialize $S \leftarrow \emptyset$, $L \leftarrow \emptyset$.
        \If{$m = 0$}
        \State \Return $(S, L)$
        \EndIf
        \State $i \leftarrow 0$
        \While{$i < m$}
        \State $current\_start \leftarrow y_i$
        \State $current\_length \leftarrow 1$
        \While{$i + 1 < m$ and $y_{i+1} = y_i + 1$}
        \State $current\_length \leftarrow current\_length + 1$
        \State $i \leftarrow i + 1$
        \EndWhile
        \State Append $current\_start$ to $S$.
        \State Append $current\_length$ to $L$.
        \State $i \leftarrow i + 1$
        \EndWhile
        \State \Return $(S, L)$
    \end{algorithmic}
\end{algorithm}

\paragraph{Compression of RLE Components}
The space efficiency of RLE hinges on effectively compressing the resulting sequences $S$ and $L$.
The run starts sequence $S = (s_1, \dots, s_p)$ is strictly monotonic. Consequently, it is an ideal candidate for Elias-Fano encoding (\autoref{sec:elias_fano_code}), leveraging its space efficiency for such sequences.

The run lengths sequence $L = (l_1, \dots, l_p)$ is a sequence of positive integers without guaranteed structure. Standard variable-length integer codes (\autoref{sec:integer_coding}), such as Elias Gamma or Delta codes, can be applied. In practice, employing a structure like the \textsf{compressed-intvec} (\autoref{app:compressed_intvec_engineering}) allows choosing an appropriate codec and provides efficient random access.

\paragraph{Random Access in RLE}
Retrieving the element $y_k$ (the element at index $k$ in the original sequence $Y$, $0 \le k < m$) from the RLE representation $(S, L)$ requires identifying the run to which $y_k$ belongs. This necessitates finding the unique run index $i^*$ (where $1 \le i^* \le p$) such that:
\[ \sum_{j=1}^{i^*-1} l_j \le k < \sum_{j=1}^{i^*} l_j \]
where the sum is defined as $0$ if $i^*=1$. Once $i^*$ is found, the value $y_k$ is given by:
\[ y_k = s_{i^*} + \left( k - \sum_{j=1}^{i^*-1} l_j \right) \]
Computing the prefix sums $\sum l_j$ on the fly requires iterating through $L$, potentially leading to $O(p)$ time complexity for access, which is inefficient if the number of runs $p$ is large.

To accelerate random access, one can precompute and store the sequence of prefix sums of the run lengths:
\[ P = (p_1, p_2, \dots, p_p) \qquad  p_i = \sum_{j=1}^{i} l_j. \]
Since $l_j \ge 1$ for all $j$, the sequence $P$ is strictly increasing. As a strictly monotonic sequence, $P$ itself can be compressed effectively, for instance, using Elias-Fano encoding.

With the prefix sum sequence $P$ available, finding the index $i^*$ corresponding to the query index $k$ reduces to searching for the smallest $i^*$ such that $p_{i^*} > k$. This is a successor search problem on the monotonic sequence $P$. Using binary search on $P$ (if stored as an array) takes $O(\log p)$ time. If $P$ is stored in a structure supporting faster searches (like rank/select structures built upon certain Elias-Fano constructions), this lookup time might be further improved. Algorithm \ref{alg:rle_get_value} formalizes access using prefix sums.

% Note: Algorithm is unchanged from the original text.
\begin{algorithm}[htbp] % Added [htbp]
    \caption{$\textsc{GetValueRLE}(S, L, P, k)$: Retrieve element from RLE representation} % Renamed for clarity
    \label{alg:rle_get_value}
    \small
    \begin{algorithmic}[1]
        \Require Run starts $S=(s_1,\dots,s_p)$, Run lengths $L=(l_1,\dots,l_p)$, Prefix sums $P=(p_1, \dots, p_p)$, index $k \in [0, m-1]$.
        \Ensure The value $y_k$ of the element at index $k$.
        \State Find smallest $i^* \in \{1, \dots, p\}$ such that $P[i^*] > k$.
        \If{$i^* = 1$}
        \State $previous\_cumulative\_length \leftarrow 0$
        \Else
        \State $previous\_cumulative\_length \leftarrow P[i^*-1]$
        \EndIf
        \State $offset \leftarrow k - previous\_cumulative\_length$
        \State $start\_value \leftarrow S[i^*]$
        \State \Return $start\_value + offset$
    \end{algorithmic}
\end{algorithm}

\paragraph{Method Selection}
The choice between direct Elias-Fano encoding and Run-Length Encoding (RLE) for representing the strictly increasing sequences $\mathcal{O}_v$ and $\mathcal{I}_v$ depends on their structure. RLE is advantageous when the sequence exhibits significant clustering, meaning the number of runs $p$ is substantially smaller than the total number of elements $m$ ($p \ll m$). In such cases, the combined compressed size of the run starts $S$ and run lengths $L$ (and potentially the prefix sums $P$) might be less than direct Elias-Fano encoding of the original sequence.

On the other hand, if sequences are sparse or lack significant runs ($p$ is close to $m$), direct Elias-Fano is likely more straightforward and potentially more space-efficient.

Regardless of the chosen compression method, representing the entire associated data component $\mathcal{D}$ practically involves concatenating the compressed representations of all sequences ($\{\mathcal{D}_E(v)\}_{v \in V_E}$ and $\{\mathcal{D}_I(v)\}_{v \in V_I}$) into a single buffer. An auxiliary index structure is then needed to map each vertex ID $v$ to the starting position and metadata of its compressed sequence. The space overhead for this index is typically negligible compared to the compressed data itself

\section{Below the Entropy Lower Bound}
\label{sec:below_entropy}

To evaluate the space efficiency of our proposed structure, we establish a baseline based on the information content in the weighted DAG itself. Drawing upon the principles of information theory outlined in \autoref{ch:Chapter2}, we can define a measure of entropy for the graph $G=(V, E, w)$.

Any \emph{lossless} representation of the graph $G$ must, at a minimum, encode the information required to uniquely specify its structure (the edges $E$) and the associated weights (the function $w$). We formulate a $0^{th}$-order entropy measure, denoted $\mathcal{H}_0(G)$, as a lower bound on the number of bits required to represent these components, assuming no prior knowledge about correlations or higher-order statistical properties.

The information content required to specify the sequence of vertex weights $(w(v))_{v \in V}$ constitutes the first component. A fundamental lower bound, denoted $\mathcal{H}_W(G)$, can be established by considering the minimal binary representation length for each individual weight:
\[ \mathcal{H}_W(G) = \sum_{v \in V} \lceil \log_2 (w(v)+1) \rceil \quad \text{bits}. \]
This measure reflects the space needed assuming each weight is encoded independently, using the minimal bits for its value (handling $w(v)=0$), without leveraging potential statistical correlations or distribution patterns suitable for techniques like variable-length integer coding (\autoref{sec:integer_coding}).

The second component relates to the graph's topology, specifically the set of edges $E$. With $n = |V|$ vertices, there exist $n(n-1)$ possible directed edges (excluding self-loops). Encoding the topology requires specifying which $m = |E|$ of these potential edges are present. Assuming all directed graphs with $n$ vertices and $m$ edges are equally probable a priori, the information content is determined by the number of ways to choose these $m$ edges. This leads to the topological information component, $\mathcal{H}_E(G)$:
\[ \mathcal{H}_E(G) = \log_2 \binom{n(n-1)}{m} \quad \text{bits}. \]
This quantity can be approximated using Stirling's formula, $\log_2 \binom{N}{k} \approx k \log_2(N/k) + O(k)$, yielding $\mathcal{H}_E(G) \approx m \log_2 \left( \frac{n(n-1)}{m} \right) + O(m)$ bits.

Combining these components gives us a formal definition for the $0^{th}$-order entropy of the weighted DAG.

\begin{definition}[$0^{th}$-Order Weighted DAG Entropy]
    \label{def:dag_entropy}
    For a weighted DAG $G = (V, E, w)$ with $n=|V|$ vertices and $m=|E|$ edges, its $0^{th}$-order entropy $\mathcal{H}_0(G)$ is defined as the sum of the information content required for the weights and the topology:
    \[ \mathcal{H}_0(G) = \sum_{v \in V} \lceil \log_2 (w(v)+1) \rceil + \log_2 \binom{n(n-1)}{m} \quad \text{bits}. \]
\end{definition}

The value $\mathcal{H}_0(G)$ represents a theoretical lower bound on the space required by any lossless encoding of the graph $(V, E, w)$ based solely on its zero-order statistics.

Our proposed succinct data structure (\autoref{sec:succinct_dag_representation}), however, is designed differently. While lossless for Rank query computation (\ref{def:rank_dag}), it is inherently \emph{lossy} concerning the reconstruction of the original graph $G$, as it does not store the complete edge set $E$. It retains only vertex weights $\mathcal{W}$, successor information $\Sigma$, and associated data $\mathcal{D}$. This distinction allows the structure's space usage, $S(G)$, to potentially fall below the $\mathcal{H}_0(G)$ bound.

To illustrate this, we analyze performance on a weighted DAG derived from unrolling a Bitcoin Peer-to-Peer temporal network graph (details of the unrolling process are beyond the scope of this thesis), having $n = 22,210$ vertices and $m = 50,514$ edges. For this specific DAG, the calculated $0^{th}$-order entropy $\mathcal{H}_0(G)$ amounts to 1,525,730 bits, comprising $\mathcal{H}_W(G) = 60,824$ bits for weights and $\mathcal{H}_E(G) = 1,464,906$ bits for topology according to \ref{def:dag_entropy}.

We compare this theoretical lower bound $\mathcal{H}_0(G)$ against theoretical estimates of the space required by our succinct structure and alternative approaches based on precomputation.

For sequences composed of general non-negative integers $x$, such as the vertex weights $\mathcal{W}$, the successor identifiers $\Sigma$, or the interval endpoints in baseline precomputation results, the space estimation is based on summing the minimal binary representation cost for each integer independently. This cost is calculated as $\lceil \log_2(x+1) \rceil$ bits per integer $x$.

When representing strictly monotonic sequences, like the run start values in RLE or interval endpoints compressed using Elias-Fano (\autoref{sec:elias_fano_code}), our space estimation relies on its established theoretical complexity. Theorem \ref{thm:ef_space_revised} guarantees an upper bound of
\[n \log_2(u/n) + 2n\]
bits for encoding $n$ integers within the range $[0, u)$ using Elias-Fano.

Finally, the space for the offset sequences $\mathcal{I}_v$ when stored using the Run-Length Encoding (RLE) scheme described in \autoref{sec:compression_strategies} is estimated by combining the previous principles. It requires the sum of the space estimate for the strictly monotonic sequence of run start values (using the Elias-Fano estimation) and the space estimate for the sequence of corresponding run lengths (using the minimal binary representation cost for each length).

\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{l r}
        \toprule
        Component / Method                                      & Estimated Bits \\
        \midrule
        \textbf{Theoretical Lower Bound ($\mathcal{H}_0(G)$)}   &                \\
        \quad $0^{th}$-Order Entropy Total                      & 1,525,730      \\
        \quad \quad Weights Component ($\mathcal{H}_W(G)$)      & 60,824         \\
        \quad \quad Topology Component ($\mathcal{H}_E(G)$)     & 1,464,906      \\
        \midrule
        \textbf{Precomputed Rank Queries}                       &                \\
        \quad Explicit Storage (Minimal Binary)                 & 4,854,533      \\
        \quad Elias-Fano Compressed Storage                     & 2,211,849      \\
        \midrule
        \textbf{Succinct DAG Representation (RLE)}              &                \\
        \quad Total Space ($S(G)$)                              & 699,779        \\
        \quad \quad Weights $\mathcal{W}$ (Minimal Binary)      & 60,824         \\
        \quad \quad Successors $\Sigma$ (Minimal Binary)        & 274,015        \\
        \quad \quad Associated Data $\mathcal{D}$ (RLE Offsets) & 364,940        \\
        \bottomrule
    \end{tabular}
    \caption{Theoretical space estimates (in bits) for the example Bitcoin DAG ($n=22,210$, $m=50,514$).}
    \label{tab:space_estimates_bitcoin}
\end{table}

Table \ref{tab:space_estimates_bitcoin} presents the results of this theoretical space estimation for the example DAG. The total estimated space for our succinct DAG representation using RLE for the offsets, $S(G)$, is 699,779 bits. This value is notably less than half of the $0^{th}$-order entropy $\mathcal{H}_0(G)$ (1,525,730 bits). This result highlights the advantage of our approach: by selectively discarding information required for full graph reconstruction (specifically, the complete edge set $E$) while preserving all information necessary for Rank query computation, the structure achieves a space footprint smaller than the theoretical minimum for lossless graph encoding.

Moreover, the analysis reveals the significant space overhead associated with precomputing Rank query results. Storing the interval sets for all nodes explicitly, even using minimal binary representations, requires an estimated 4,854,533 bits. Applying Elias-Fano compression to these precomputed results reduces the space to 2,211,849 bits. While this represents a substantial saving over the explicit form, it remains considerably larger than both the $0^{th}$-order entropy bound and, crucially, the space achieved by our succinct DAG representation ($S(G)$). Therefore, our structure provides not only a mechanism to answer complex path queries but does so with remarkable space efficiency, far surpassing precomputation strategies and falling below the conventional entropy bounds associated with lossless graph representation due to its targeted, query-specific information retention.
