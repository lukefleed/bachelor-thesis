\appendix
\chapter{Engineering a Compressed Integer Vector}
\label{app:compressed_intvec_engineering}

\noindent This appendix outlines the design principles and engineering considerations behind \emph{compressed-intvec}, a software library that we developed for the efficient storage and retrieval of integer sequences \cite{compressed-intvec}. The library leverages the variable-length integer coding techniques discussed in \autoref{sec:integer_coding} to achieve significant space savings compared to standard fixed-width representations, while providing mechanisms for acceptably fast data access.

\paragraph{Motivation and Bitstream Abstraction}
Storing sequences of integers, particularly when many values are small or follow predictable patterns, using standard fixed-width types (such as 64-bit integers) is inherently wasteful. Variable-length integer codes, such as Unary, Gamma, Delta, and Rice codes (\autoref{sec:integer_coding}), offer a solution by representing integers using a number of bits closer to their information content, assigning shorter codes to smaller or more frequent values.

However, these codes produce binary representations of varying lengths, not necessarily aligned to byte or machine word boundaries. Therefore, storing a sequence of integers compressed with these methods requires packing their binary codes contiguously into a single, undifferentiated sequence of bits, commonly referred to as a bitstream. This necessitates the use of specialized bitstream reading and writing capabilities, abstracting away the complexities of bit-level manipulation. The implementation described here relies on the \texttt{dsi-bitstream} library for this purpose \cite{dsi-bitstream}, ensuring that the variable-length codes can be written to and read from memory efficiently. The fundamental requirement for correctly decoding the concatenated sequence is the prefix-free (self-delimiting) property of the chosen integer code, which guarantees that the end of one codeword can be determined without ambiguity before reading the next.

\paragraph{Addressing Random Access via Sampling}
While bitstream concatenation enables compression, it introduces a significant challenge for random access. Retrieving the $i$-th integer from the original sequence cannot be done by calculating a simple memory offset, as the bit lengths of preceding elements are variable. A naive approach would require sequentially decoding the first $i$ integers from the beginning of the bitstream, resulting in an unacceptable $O(i)$ access time.

To provide efficient random access, the \emph{compressed-intvec} library employs a \emph{sampling} technique. During the encoding phase, the absolute starting bit position of every $k$-th integer in the sequence is recorded. These positions, or samples, are stored in an auxiliary data structure, typically a simple array. The value $k$ is a user-configurable sampling parameter that dictates a trade-off between random access speed and the memory overhead incurred by storing the samples.

To retrieve the $i$-th integer, the library first determines the index of the sample corresponding to the block containing the $i$-th element: $\texttt{sample\_idx} = \lfloor i / k \rfloor$. It retrieves the bit offset $\texttt{start\_bit}$ associated with this sample. The bitstream reader can then jump directly to this position. From $\texttt{start\_bit}$, the decoder only needs to perform $i \pmod k$ sequential decoding operations to reach and return the desired $i$-th integer. If $k$ is considered a constant (e.g., 32 or 64), this reduces the expected time complexity for random access to $O(1)$, assuming the underlying bitstream operations and single-integer decoding are sufficiently fast. The space overhead for the samples is approximately $O((n/k) \log(\text{total\_bits}))$, which is generally sub-linear in the size of the compressed data for practical values of $k$. The choice of $k$ allows tuning the balance between faster access (smaller $k$) and lower memory usage (larger $k$).

\paragraph{Codec Flexibility and Data Distribution}
The theoretical discussion in \autoref{sec:integer_coding} highlights that the efficiency of different integer codes is highly dependent on the statistical distribution of the integers being compressed. For example, Gamma code is suited for distributions decaying roughly as $1/x^2$, Rice codes excel for geometrically distributed values (especially when integers cluster around multiples of $2^k$), and minimal binary coding is optimal for uniformly distributed data within a known range \cite{ferragina2023pearls}.

Recognizing this dependency, the \emph{compressed-intvec} library is designed with flexibility in mind. It employs generic programming paradigms (specifically, Rust traits) to allow the user to select the most appropriate integer coding scheme (\emph{codec}) for their specific data distribution at compile time. The library provides implementations for several standard codecs, including Gamma, Delta, Rice, and Minimal Binary \cite{compressed-intvec}. Some codecs, like Rice or Minimal Binary, require additional parameters (the Rice parameter $k$ or the universe upper bound $u$, respectively), which are also managed by the data structure. Selecting a codec poorly matched to the data can significantly degrade compression performance, potentially even increasing the storage size compared to an uncompressed representation \cite{compressed-intvec}. This flexibility is therefore crucial for achieving optimal results in practice.
