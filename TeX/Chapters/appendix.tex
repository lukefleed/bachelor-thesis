\appendix
\chapter{Engineering a Compressed Integer Vector}
\label{app:compressed_intvec_engineering}

\noindent This appendix outlines the design principles and engineering considerations behind \emph{compressed-intvec}, a software library that we developed for the efficient storage and retrieval of integer sequences \cite{compressed-intvec}. The library leverages the variable-length integer coding techniques discussed in \autoref{sec:integer_coding} to achieve significant space savings compared to standard fixed-width representations, while providing mechanisms for fast random access.

\paragraph{Bitstream Abstraction}
Storing sequences of integers, particularly when many values are small or follow predictable patterns, using standard fixed-width types (such as 64-bit integers) is inherently wasteful. Variable-length integer codes, such as Unary, Gamma, Delta, and Rice codes (\autoref{sec:integer_coding}), offer a solution by representing integers using a number of bits closer to their information content, assigning shorter codes to smaller or more frequent values.

However, codes produce binary representations of varying lengths, not necessarily aligned to byte or machine word boundaries. Therefore, storing a sequence of integers compressed with these methods requires packing their binary codes contiguously into a single, undifferentiated sequence of bits, commonly referred to as a bitstream. This necessitates the use of specialized bitstream reading and writing capabilities, abstracting away the complexities of bit-level manipulation. The implementation described here relies on the \texttt{dsi-bitstream} library for this purpose \cite{dsi-bitstream}, ensuring that the variable-length codes can be written to and read from memory efficiently. The fundamental requirement for correctly decoding the concatenated sequence is the prefix-free (self-delimiting) property of the chosen integer code, which guarantees that the end of one codeword can be determined without ambiguity before reading the next.

\paragraph{Random Access via Sampling}
While bitstream concatenation enables compression, it introduces a significant challenge for random access. Retrieving the $i$-th integer from the original sequence cannot be done by calculating a simple memory offset, as the bit lengths of preceding elements are variable. A naive approach would require sequentially decoding the first $i$ integers from the beginning of the bitstream, resulting in an unacceptable $O(i)$ access time.

To provide efficient random access, the \emph{compressed-intvec} library employs a \emph{sampling} technique. During the encoding phase, the absolute starting bit position of every $k$-th integer in the sequence is recorded. These positions, or samples, are stored in an auxiliary data structure, typically a simple array. The value $k$ is a user-configurable sampling parameter that dictates a trade-off between random access speed and the memory overhead incurred by storing the samples.

To retrieve the $i$-th integer, the library first determines the index of the sample corresponding to the block containing the $i$-th element: $\texttt{sample\_idx} = \lfloor i / k \rfloor$. It retrieves the bit offset $\texttt{start\_bit}$ associated with this sample. The bitstream reader can then jump directly to this position. From $\texttt{start\_bit}$, the decoder only needs to perform $i \pmod k$ sequential decoding operations to reach and return the desired $i$-th integer. If $k$ is considered a constant, this reduces the expected time complexity for random access to $O(1)$\footnote{The underlying bitstream operations and single-integer decoding are sufficiently fast to assume that}. The space overhead for the samples is approximately $O((n/k) \log(\text{total\_bits}))$, which is generally sub-linear in the size of the compressed data for practical values of $k$. The choice of $k$ allows tuning the balance between faster access (smaller $k$) and lower memory usage (larger $k$).

\paragraph{Codec Flexibility}
The compression effectiveness of various integer coding techniques, as detailed in \autoref{sec:integer_coding}, is highly contingent upon the statistical properties of the integer sequence being encoded. For instance, Gamma coding is generally well-suited for distributions exhibiting decay proportional to $1/x^2$, Rice codes demonstrate efficiency for geometrically distributed data, and Minimal Binary coding provides optimal compression for integers uniformly distributed within a known range $[0, u)$.

This data-dependent performance necessitates adaptability in the choice of coding scheme (\emph{codec}). The \emph{compressed-intvec} library achieves this through an abstraction mechanism based on Rust traits. These traits define a formal interface that different codec implementations must satisfy, allowing the library's core logic to remain agnostic to the specific encoding details. Consequently, the user can parameterize the compressed vector type with the most suitable codec implementation for their particular data distribution at compile time. The selection of an inappropriate codec relative to the data's characteristics can substantially degrade compression performance, potentially yielding a representation larger than the uncompressed equivalent.
