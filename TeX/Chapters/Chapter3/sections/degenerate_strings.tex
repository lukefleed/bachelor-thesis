\section{Degenerate Strings} \label{sec:degenerate_strings}
% Brief introduction to degenerate strings \cite{fischer1974string, alzamel2018degenerate}
Given a finite non-empty alphabet $\Sigma$, a \emph{string} $X$ of length $N$ over $\Sigma$ is a sequence of $N$ symbols from $\Sigma$. We denote with $\Sigma^*$ the sets of all the strings in $\Sigma$, including the trivial one $\epsilon$ on length $0$. We can now introduce the concept of a \emph{degenerate string}, presented for the first time by Fischer and Paterson in 1974 \cite{fischer1974string} and has been used in various contexts since then \cite{alzamel2018degenerate}.

\begin{definition}[Degenerate String]\label{def:degenerate_string}
    A \emph{degenerate string} is a sequence $X = X_1 X_2 \ldots X_n$, where each $X_i$ is an element of $\Sigma^*$. We call $n$ the \emph{length} of $X$ and $N = \sum_{i=1}^{n} |X_i|$ the \emph{size} of $X$.
\end{definition}

\begin{definition}[Balanced Degenerate String]\label{def:balanced_degenerate_string}
    TODO
\end{definition}

\todo[inline]{TODO: Add an example of a degenerate string and add a few more lines to clarify the concept. Talk about their application in bioinformatics and why the literature is interested in them.}

\subsection{Subset-Rank and Subset-Select} \label{sec:subset_rank_select}
We have seen in depth the rank and select operations in \autoref{sec:bitvectors}. Where given a string $S$ from an alphabet $[1,\sigma]$, we showed how to answer the following queries efficiently:
\begin{itemize}
    \item $rank_S(c, i)$: the number of occurrences of the symbol $c$ in $S[1..i]$.
    \item $select_S(c, i)$: the position of the $i$-th occurrence of the symbol $c$ in $S$.
\end{itemize}
We can now extend these operations to degenerate strings. This problem was recently studied for the first time by Alanko, Biagi, Puglisi and Vuohtoniemi in \cite{SubsetWT}, where their goal was to support the following queries on degenerate strings:
\begin{itemize}
    \item $\texttt{subset-rank}_X(c, i)$: the number of sets in $X[1..i]=X_1 \dots X_i$ that contain the symbol $c$.
    \item $\texttt{subset-select}_X(c, i)$: the position of the $i$-th set that contains the symbol $c$
\end{itemize}
\begin{example}
    Let's consider the following degenerate string over the alphabet $\Sigma = \{A, B, C, D\}$:
    \[
        X = \{AAB\} \{CD\} \{\} \{A\} \{BCD\} \{\} \{C\} \{AB\} \{\} \{D\}
    \]
    Then for example we would have
    \begin{equation*}
        \texttt{subset-rank}_X(C, 6) = 2 \qquad \texttt{subset-select}_X(A, 2) = 3
    \end{equation*}
    since the symbol $C$ appears in order in the sets $\{CD\}$ and $\{BCD\}$ and the second set containing the symbol $A$ is $\{A\}$ ad index $3$.
\end{example}
% The interest in performing this types of queries comes from different problems that aries in pangenomics. In our case, the motivation that lead the authors of \cite{SubsetWT} to study this problem was to support fast membership queries on de Bruijn graphs. In particular in \cite{alanko2023small} the same authors defined the \emph{Spectral Burrows-Wheeler Transform} (\texttt{SBWT}): a particular sequence of subsets of the alphabet of the string that encodes $k$-spectrum of the string. With the \texttt{SBWT} they show how to represent the de Bruijn graph of all length-$k$ substrings of a string $S$ in a way that allows to answer membership queries by performing $2k$ \texttt{subset-rank} queries on the \texttt{SBWT} of $S$. In their experimentation, their approach that, compared to the state-of-the-art, its two order of magnitude faster if the space occupancy remains the same and one order of magnitude faster with improved space occupancy.
\noindent This type of queries are crucial for solving various problems encountered in pangenomics, the study of entire genomes across a species. In the context of de Bruijn graphs, which can be used to represent relationships between overlapping substrings in biological sequences, researchers in \cite{SubsetWT} aimed to enable efficient membership queries. \vspace{0.4cm}

\noindent Building upon this work, in \cite{alanko2023small} they introduced the \emph{Spectral Burrows-Wheeler Transform} (SBWT). This transform represents a string's $k$ spectrum (the collection of all $k$-length substrings) as a sequence of alphabet subsets, i.e a degenerate string. The authors demonstrated that the SBWT allows for efficient de Bruijn graph representation of all $k$-length substrings in a string $S$. Membership queries within this graph can be answered using just $2k$ \texttt{subset-rank} queries on $S$'s SBWT. \vspace{0.4cm}

\noindent Their experiments revealed significant performance improvements compared to previously \todo{Not anymore since in \cite{bille2023rank} they improved everything} existing methods. Their approach achieves two orders of magnitude faster query times while maintaining the same space usage. Additionally, with improved space efficiency, it offers a one order of magnitude speedup. \vspace{0.4cm}

\todo[inline]{There is the big problem that in \cite{bille2023rank} they revisit the rank-select problem on degenerate strings, introducing a new, natural parameter and reanalyzing existing reductions to rank-select on regular strings. Plugging in standard data structures, the time bounds for queries are improved exponentially while essentially matching, or improving, the space bounds. Furthermore, they provide a lower bound on space that shows that the reductions lead to succinct data structures in a wide range of cases. Their most compact structure matches the space of the most compact structure of Alanko et al. \cite{SubsetWT} while answering queries twice as fast. They also provide an implementation using modern vector processing features; it uses less than one percent more space than the most compact structure of Alanko et al. \cite{SubsetWT} while supporting queries four to seven times faster, and has competitive query time with all the remaining structures.}

\vspace{0.4cm}
\noindent There is of course a naive and straightforward way to support these queries in $O(1)$. Given a degenerate string $X$ of length $n$ over an alphabet $\Sigma=[1,\sigma]$, for each $c \in \Sigma$ store a bitmap $B_c$ of length $n$ where the $i$-th bit is set to $1$ if and only if $c$ is in $X_i$. This way we can answer the queries in $O(1)$ time. In fact,
\begin{equation*}
    \texttt{subset-rank}_X(c, i) = rank_{B_c}(1, i)
\end{equation*}
However, this approach requires $O(\sigma n)$ bits of space, which is not efficient if the alphabet is large or the degenerate string is long.

\subsubsection{Subset Wavelet Trees} \label{sec:subset_wavelet_trees}
In order to support the subset-rank and subset-select queries on degenerate strings, Alanko et al. \cite{SubsetWT} introduced the \emph{Subset Wavelet Tree} (SWT). This data structure is built on top of the Wavelet Tree (WT) \cite{GrossiWT2003} (already covered in \autoref{sec:wavelet_trees}) and extends it to handle degenerate strings. In this section, we will first see how the SWT is constructed and then how it can be used to answer subset-rank and subset-select queries efficiently.

\subsubsection*{Structure} \label{sec:swt_structure}

Imagine we have an alphabet with $\sigma = 2^n$ symbols, where n is a natural number. We can recursively construct a tree with $\sigma$ levels to represent all possible subsets of this alphabet. Each node in the tree corresponds to a unique subset. The root node represents the entire alphabet. Each child node of a node $v$ represents a subset, $A_v$, derived from its parent's alphabet. Let's delve deeper into this recursive process. For each node (except the root), we define its child nodes as follows: the left child represents the first half of the parent's alphabet, while the right child represents the second half. \vspace{0.4cm}

\noindent We also introduce $Q_v$, a subsequence containing all subsets that include at least one element from $A_v$. Notably, when $A_v$ represents the entire alphabet, $Q_v$ also includes the empty set. In addition to representing subsets, each node $v$ in our tree holds two bit vectors, $L_v$ and $R_v$, with a length equal to the size of the corresponding subsequence $Q_v$.
\begin{itemize}
    \item $L_v[i] = 1$: This indicates that the $i$-th subset in $Qv$ contains at least one character from the \emph{first half} of the alphabet associated with node $v$ ($Av$).
    \item $R_v[i] = 1$: This indicates that the $i$-th subset in $Q_v$ contains at least one character from the \emph{second half} of the alphabet associated with node $v$ ($A_v$).
\end{itemize}
We can leverage these bit vectors $L_v$ and $R_v$ to create a single string using the alphabet \{0, 1, 2, 3\}. The $i$-th character in this string is formed by a simple calculation:
\begin{equation}
    S_v[i] = 2 \cdot R_v[i] + L_v[i]
\end{equation}
This formula essentially packs the information from both bit vectors into a single digit. A value of $0$ indicates the subset doesn't contain elements from either half, $1$ signifies the first half only, $2$ signifies the second half only, and $3$ represents elements from both halves. \vspace{0.4cm}

\subsubsection{Subset-Rank Queries} \label{sec:subset_rank_queries}

\noindent The bit vectors $L_v$ and $R_v$ enable efficient rank queries. To find the rank of a character $c$ at position $i$ in the original alphabet, we perform the following steps:
\begin{enumerate}
    \item \textbf{Traverse the Tree}: We navigate from the root node down to the leaf node where the associated alphabet $A_v$ is the single-element set containing only character $c$.
    \item \textbf{Prefix Length Calculation}: During this traversal, for each visited node $v$, we calculate the length of the prefix within the current subsequence $Qv$. This prefix encompasses all subsets in the original data $(X_1,\dots, X_i)$ that include at least one character from $A_v$. Similar to traditional wavelet tree queries, we leverage rank queries on the $L_v$ and $R_v$ bit vectors to determine this prefix length.
\end{enumerate}
Algorithm \ref{alg:subset-rank} offers pseudocode for this approach.

\subsubsection{Subset-Select Queries} \label{sec:subset_select_queries}

To answer subset-select queries, we follow a similar process to subset-rank queries.

\begin{enumerate}
    \item \textbf{Traversal from Leaf to Root:} We begin at the leaf node where the associated alphabet $A_v$ is the single-element set containing only character $c$. We then traverse back towards the root node.
    \item \textbf{Updating Position} ($i$): As we move through each node $v$ during traversal, we adjust the position $i$.
    \item \textbf{Prefix Length with $c$ Characters}: We calculate the length of the prefix within the current subsequence $Qv$. This prefix encompasses all subsets in the original data $(X_1,\dots, X_i)$ that collectively contain exactly $i$ occurrences of character $c$. As done before, we use select queries on the $L_v$ and $R_v$ bit vectors to determine this prefix length.
\end{enumerate}

\noindent Algorithm \ref{alg:subset-access} provides pseudocode for this approach. This method leverages the bit vectors to efficiently locate specific character occurrences without iterating through the entire dataset.

\begin{algorithm}[h]
    \caption{Subset-Rank Query}
    \label{alg:subset-rank}
    \begin{algorithmic}[1]
        \Require $c$: character from $[1, \sigma]$, $i$: index
        \Ensure The number of subsets $X_j$ such that $j \leq i$ and $c \in X_j$
    \end{algorithmic}
    \begin{algorithmic}
        \Function{Subset-Rank}{$c, i$}
        \State $v \gets \text{root}$
        \State $[l, r] \gets [0, \sigma]$ \Comment{\small{Range of alphabet indices}}
        \While{$l \neq r$}
        \If{$c \leq \frac{l+r}{2}$}
        \State $r \gets \left\lfloor \frac{l+r}{2} \right\rfloor$
        \State $i \gets rank_1(L_v, i)$
        \State $v \gets \text{left child of } v$
        \Else
        \State $l \gets \left\lceil \frac{l+r}{2} \right\rceil$
        \State $i \gets rank_1(R_v, i)$
        \State $v \gets \text{right child of } v$
        \EndIf
        \EndWhile
        \State \Return $i$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
    \caption{Subset-Select Query}
    \label{alg:subset-access}
    \begin{algorithmic}[1]
        \Require $c$: character from $[1, \sigma]$, $i$: index
        \Ensure The position of the $j$-th subset such that the $i$-th $c \in X_j$
    \end{algorithmic}
    \begin{algorithmic}
        \Function{Subset-Select}{$c, i$}
        \State $v \gets \text{leaf node with alphabet } A_v = \{c\}$
        \While{$v \neq \text{root}$} \Comment{\small{Traverse from leaf to root}}
        \State $u \gets \text{parent of } v$
        \If{$v = \text{left child of } u$}
        \State $i \gets select_1(L_v, i)$
        \Else
        \State $i \gets select_1(R_v, i)$
        \EndIf
        \State $v \gets u$
        \EndWhile
        \State \Return $i$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\subsubsection*{Space Complexity}
The subset wavelet answer subset rank and select queries in logarithmic time $(O(\log \sigma))$, since at each level (there are $\log \sigma$ levels) we perform constant time operations. However, the actual number of bits used vary based on the data we are working with. For a general set sequence, it's typically $2n(\sigma - 1) + o(n\sigma)$ bits. \vspace{0.4cm}

\noindent Visualizing the tree as a complete binary tree with $\sigma$ leaves (not explicitly stored) helps. If the sets are full, each internal node stores $2n$ bits\footnote{Since each set goes both to the left and to the right child at each level}, leading to a total space complexity of $(\sigma - 1)2n$ due to the number of internal nodes and their size. However, for balanced degenerate strings \ref{def:balanced_degenerate_string} (where most sets have one element), space usage improves. Since each set element corresponds to at most one symbol per level, the total sequence length is bounded by set sizes. This translates to a space complexity of $2n log \sigma$ bits across all $log \sigma$ tree levels. \vspace{0.4cm}

\noindent We can sum this up in the following theorem

\begin{theorem}[Space Complexity of Subset Wavelet Trees] \label{thm:swt_space}
    The subset wavelet tree of a balanced degenerate string takes $2n \log \sigma + o(n \log \sigma)$ bits of space and supports subset-rank and subset-select queries in $O(\log \sigma)$ time.
\end{theorem}

\todo[]{The $o(n \log \sigma)$ term in the space complexity is due to...? The space required to store the bitvectors?}

\subsubsection*{Rank for Base-$3$ and Base-$4$ Alphabets}

The subset wavelet tree (SWT) relies on efficiently answering regular rank queries on small alphabet sequences stored within its nodes. At the root node, the sequence uses a base-4 alphabet ($\Sigma = \{0, 1, 2, 3\}$), while all other nodes use a base-3 alphabet ($\Sigma = \{0, 1, 2\}$). \vspace{0.4cm}

\noindent However, the SWT requires a more specific operation than a standard rank query. It needs the sum of two rank queries: $rank(i, \Sigma - 1)$ and either $rank(i, \Sigma[0])$ or $rank(i, \Sigma[1])$. We call these combined operations \emph{rank-pair queries}. Here's how we can express rank-pair queries for base-4

\begin{align}
    rankpair(i,1) & = rank(i,1) + rank(i,3) \\
    rankpair(i,2) & = rank(i,2) + rank(i,3)
\end{align}

\noindent For base-3 alphabets, we can express rank-pair queries as follows:

\begin{align}
    rankpair(i,0) & = rank(i,0) + rank(i,2) \\
    rankpair(i,1) & = rank(i,1) + rank(i,2)
\end{align}

\noindent In the following section we will see different methods that Alanko et al. \cite{SubsetWT} proposed to answer rank and rank-pair queries on base-3 and base-4 alphabets. They developed these structures with the a clear and very specific goal in mind: answer efficiently membership queries on Spectral Burrows Wheeler Transform (SBWT) sequences. Moreover, they focused on 3 particular genomics dataset and exploited their specific proprieties to develop the most efficient data structures for their needs. This datasets are commonly used for $k$-mer indexing in bioinformatics and are the following:

\begin{enumerate} \label{datasets}
    \item \textbf{E. coli Pangenome:} This dataset consists of 3,682 E. coli genomes downloaded in 2020. It represents a subset of assemblies from NCBI's GenBank database\footnote{\url{ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/bacteria/assembly\_summary.txt}} filtered for "Escherichia coli" and downloaded before March 22nd, 2016. The complete dataset is available at\footnote{\url{zenodo.org/record/6577997}}.
    \item \textbf{Human Gut Illumina Reads:} This dataset contains 17,336,887 short DNA sequences (reads) of length 502 base pairs obtained from a study on human gut microbiota\footnote{SRA identifier ERR5035349} investigating irritable bowel syndrome and bile acid malabsorption \cite{jeffery2020differences}.
    \item \textbf{SARS-CoV-2 Genomes:} This dataset comprises 1,234,695 complete genomes of the SARS-CoV-2 virus, downloaded from NCBI datasets.
\end{enumerate}

\noindent The authors shows that when the Spectral Burrows Wheeler Transform (SBWT) is built on these datasets, the resulting degenerate strings present a very skewed distribution of the alphabet symbols, with the vast majority of the sets containing only one element.

\subsection{Rank Methods for Subset Wavelet Trees} \label{sec:rank_succint_datastructures}
In \cite{SubsetWT} they compare 5 methods that supports \texttt{rank} and \texttt{rank-pairs} queries on small alphabet sequences (they need it to answer those queries on the sequences stored at the nodes of the subset wavelet tree).

\subsubsection{Wavelet Trees}

In their paper, Alanko et. al acknowledge the wavelet tree (\autoref{sec:wavelet_trees}) as the current go-to method for performing rank queries on sequences with non-binary alphabets. Wavelet trees will serve as a baseline for comparison with the other data structures they will evaluate. \vspace{0.4cm}

\noindent We have seen in \autoref{sec:wavelet_trees} that we can implement the wavelet trees in different ways, different choices can influence the trade-off between space usage and query speed. The authors experimented with two options: standard bitvectors (faster but larger, \autoref{sec:wavelet_trees}) and RRR bitvectors (smaller but slower, as explained in \autoref{subsec:compressing_bitvectors}). \vspace{0.4cm}

\noindent They specifically used implementations from the Succinct Data Structures Library (SDSL)\footnote{\url{https://github.com/simongog/sdsl-lite}} because they are known to be the fastest available WT implementations\footnote{The SDSL library does not provide an implementation for rank-pairs queries, but they are just the sum of two rank queries, so they can be easily implemented on top of the rank queries.}. \vspace{0.4cm}

\todo[inline]{I have a lot of doubts about this: why don't use an huffman shaped wavelet tree? Why didn't they try to adapt the wavelet tree to this type of queries?} \vspace{0.4cm}

\todo[inline]{There are multiple possible implementations of the WT in the SDSL (all immutable): Balanced wavelet (wt\_blcd), Balanced wavelet tree for integer alphabets (wt\_int), Wavelet matrix for integer alphabets (wm\_int), Huffman-shaped wavelet tree (wt\_huff), Hu-Tucker-shaped wavelet tree (wt\_hutu), Run-length compressed wavelet tree (wt\_rlmn), Fast select wavelet tree for integer alphabets (wt\_gmr). \vspace{0.4cm}

    \noindent TODO: Check their code to see which one they used both for the standard and the RRR version.}

\subsubsection{Scanning Rank}

The data structure comprises three layers to efficiently store and query the sequence \(X\).


\begin{itemize}
    \item \textbf{Highest Layer:} This layer divides \(X\) into superblocks of size \(s\) and maintains a table storing $rank(i,c)$ for each symbol $c \in \Sigma$ and each superblock starting at position \(i\). We can store these counts in a table of size $\sigma n / s$ words, so that we can access the count for any superblock $j$ at the column $j/s$ in constant time.
    \item \textbf{Middle Layer:} This layer further divides \(X\) into blocks of size \(b\), a divisor of \(s\). For each block starting at \(i\), precomputed counts of each symbol \(c\) are stored, specifically the occurrences of \(c\) in the range between the block's start and its enclosing superblock's start. With \(s=2^{32}\), these counts require 32 bits each.
    \item \textbf{Lowest Layer:} This layer directly stores the sequence, packing 32 base-4 symbols per 64-bit word. This layer occupies approximately $64 \cdot \lceil n/32 \rceil$ bits of space, where \(n\) is the length of \(X\).
\end{itemize}

\noindent A key optimization interleaves these counts with the actual sequence data within each block. In memory, a block consists of a 2-word header storing four (precomputed) counts, followed by \(b/64\) words containing the packed symbols. This interleaving let us store the lower and middle layers in a single array $A$ of $(2n/b + n/32)$ words (i.e., $64 \cdot (2n/b + n/32)$ bits) in memory. This ensures that the data structure is cache-friendly, as the entire structure can be loaded into memory in a single read operation.

\subsubsection*{Rank Queries}

\noindent To answer \(rank(i,c)\) queries with this structure, we follow these steps:
\begin{enumerate}
    \item Locate the block containing position \(i\).
    \item Retrieve the count for \(c\) from its header.
    \item Add this count to the corresponding count from the superblock table.
    \item Scan the block's data section to count occurrences of \(c\) up to position \(i\).
\end{enumerate}

\todo[inline]{TODO: add pseudocode for the rank query.}

\noindent This scanning typically involves examining whole words and possibly one partial word, which collectively contain the relevant part of the input sequence. Counting occurrences of bit patterns within these words is accelerated through bitwise operations. Notably, $rank-pair$ achieves a particularly fast implementation by using a single bitwise \texttt{AND}\footnote{\url{https://en.cppreference.com/w/cpp/language/operator_logical}} and a single \texttt{popcount}\footnote{\url{https://en.cppreference.com/w/cpp/numeric/popcount}} operation to count relevant symbol occurrences within a word.

\subsubsection{Sequence Splitting}

The authors propose a novel data structure designed to efficiently represent sequences with skewed distributions of symbols, such as those observed in subset sequences (TODO\todo{add a picture with the distributions}). The key idea is to exploit the dominance of certain symbols (e.g., 1 and 2 in base-4 sequences) by splitting the sequence into multiple components. \vspace{0.4cm}

\noindent Given a base-4 sequence \(X\) of length \(n\), we use the following components:
\begin{itemize}
    \item \textbf{Bitvector} \(\mathbf{L}\) representing the subsequence \(X_{1,2}\) (only symbols 1 and 2), where each bit indicates whether the corresponding symbol is 1 (0) or 2 (1)
    \item \textbf{Bitvector} \(\mathbf{R}\) representing the subsequence \(X_{0,3}\) (only symbols 0 and 3), with each bit indicating whether the corresponding symbol is 0 (0) or 3 (1)
    \item \textbf{Predecessor data structure} \(\mathbf{P}\) storing the positions \(i\) where \(X[i] \in \{0, 3\}\). Both \(L\) and \(R\) are equipped with rank support structures, enabling efficient rank queries.
\end{itemize}

\noindent In skewed distributions, most sets are singletons. This means \(X_{1,2}\) will be long, while \(X_{0,3}\), $P$, and $R$ will be relatively small. This compression is especially beneficial for memory-constrained scenarios. For base-3 sequences, the bitvector \(L\) is omitted, as the predecessor structure \(P\) already stores the indices of the non-singleton sets (where \(X[i] = 2\)).

\subsubsection*{Rank Queries}

Answering Rank queries on base-4 sequences, denoted as \(\textrm{rank}_X(i, c)\), involves two steps:

\begin{itemize}
    \item \textbf{Predecessor Query}: A predecessor query on \(P\) is performed for position \(i\), returning \(p\), the number of elements in \(P\) smaller than \(i\) (i.e., the rank of the predecessor of \(i\) in \(P\)).

    \item \textbf{Binary Rank Query:}  The result of the predecessor query, \(p\), is subtracted from \(i\) to obtain the appropriate index for a binary rank query. If \(c \in \{1, 2\}\), the query is performed on bitvector \(L\):
          \begin{align}
              \textrm{rank}_X(i, 1) & = \textrm{rank}_L(i-p, 0) \\
              \textrm{rank}_X(i, 2) & = \textrm{rank}_L(i-p, 1)
          \end{align}
          If \(c \in \{0, 3\}\), the query is performed on bitvector \(R\):
          \begin{align}
              \textrm{rank}_X(i, 0) & = \textrm{rank}_R(p, 0) \\
              \textrm{rank}_X(i, 3) & = \textrm{rank}_R(p, 1)
          \end{align}
\end{itemize}

\noindent Rank queries on base-3 sequences follow the same pattern as for base-4 sequences when dealing with singletons (\(x \in \{0,1\}\)). More precisely
\begin{align}
    \textrm{rank}_X(i, 0) & = \textrm{rank}_R(i-p, 0) \\
    \textrm{rank}_X(i, 1) & = \textrm{rank}_L(i-p, 1)
\end{align}
\noindent Since there's no second binary vector, the result of the predecessor query directly gives the rank for \(c=2\). \vspace{0.4cm}

\noindent On the other hand, with this data structure, \emph{rank-pair} queries can be answered more efficiently than two separate rank queries. This is because the predecessor query, which computes \(p\), needs to be performed only once for both symbols in the query.


\subsubsection{Generalized RRR}

For this final method, the authors present a generalization of the RRR entropy compressed bitvector (see \autoref{subsec:rank} and \cite{RRR2002}) to accommodate base-3 and base-4 sequences. While generalizations of RRR exist in the literature \cite{ferragina2007compressed}, this specific adaptation draws inspiration from the work of Navarro and Providel \cite{navarro2012fast}. \vspace{0.4cm}

\noindent Let \(X\) be a sequence of length \(n\) from a constant-sized alphabet \(\sigma\). To efficiently answer rank queries, we employ a three-level indexing structure similar to the basic binary RRR structure. We divide \(X\) into blocks of size \(b = O(\log n)\) and group them into superblocks of size \(B = O(\log n)\), where \(B\) is a multiple of \(b\). For each superblock, we precompute the counts of all symbols \(\sigma\) up to its starting position, storing these counts using \(O(\log n)\) bits each. For each block, we precompute the counts of all symbols \(\sigma\) within the block, storing them using \(O(\log \log n)\) bits each. The total space required for these precomputed counts is \(O(n \sigma \log \log n / \log n) = o(n)\) since \(\sigma\) is constant. \vspace{0.4cm}

\noindent A rank query \(\textrm{rank}(i, c)\) is then answered by: (i) Looking up the precomputed count of symbol \(c\) up to the start of the superblock containing position \(i\). (ii) Summing the precomputed counts of symbol \(c\) in the blocks preceding index \(i\) within the superblock. (iii) Counting the occurrences of symbol \(c\) in the prefix of length \(p = i \mod b\) within the block containing index \(i\). \vspace{0.4cm}


\noindent To determine the symbol count within a block's prefix, additional meta-information is encoded for decoding the block's symbol sequence. Then, we loop to count the occurrences of symbol \(c\) within the prefix of length $i \mod b$. The authors introduce a equivalence relation within all the possibile $\sigma^b$ blocks, such that two blocks are equivalent if and only if they contain tha same multiset of symbols\footnote{A multiset is a generalization of the concept of a set that, unlike a set, allows multiple instances of the same element.}. We can use the equivalence classes to efficiently choose the meta-information to store: each block will store the rank $r$ of the block within the lexicographically sorted list of all the blocks in the same equivalence class.

\subsubsection*{The \texttt{unrank} Function}

\noindent The class and the lexicographically rank of the block within the class completely determine the block's content (i.e the sequence of symbols it contains). This means that we can define a function
$$\textrm{unrank}(r,d_0, \dots, d_{\sigma-1})$$
that takes as input the lexicographic rank $r$ and the precomputed counts of the symbols in the block and returns the block's content. A naive implementation of this function would require to precompute and store all the possibile answers to the function, similarly to the third layer (the lookup table) of the RRR rank data structure. However, for large values of $b$ this is not feasible. \vspace{0.4cm}

\noindent Given the \emph{multinomial coefficient}
\begin{equation} \label{eq:multinomial}
    \binom{n}{d_0d_1 \dots d_{\sigma-1}} = \frac{n!}{d_0!d_1! \dots d_{\sigma-1}!}
\end{equation}
defined so that the value is $0$ if the sum of the $d_i$ is greater than $n$ or if any of the $d_i$ is negative. We can introduce the lexicographic rank of a block $c_0, c_1, \dots, c_{b-1}$ in the equivalence class as
\begin{equation} \label{eq:lexrank}
    \textrm{lexrank}(c_0, c_1, \dots, c_{b-1}) = \sum_{i=0}^{b-1} \sum_{j=0}^{c_i -1} \binom{b-1-i}{D_0(i) ~ \dots ~ D_j(i) -1 ~ \dots ~ D_{\sigma-1}(i)}
\end{equation}
where $D_k(i)$ is the number of occurrences of the symbol $k$ in the suffix of length $i$ of the block\footnote{$c_i, \dots, c_{b-1}$}. This function can be computed in $O(b \sigma)$ time. The term $-1$ that appears in the choices of the multinomial is there to avoid counting the block itself. \vspace{0.4cm}

\noindent Formula \ref{eq:lexrank} is a process that iterates through the symbols within a block from left to right, computing different ways to choose the remaining symbols in the block using the remaining counts, with the constraint that the complete block must be lexicographically smaller than the current block. The \texttt{unrank} function essentially reverses the \texttt{lexrank} function. This can be done by incrementally adding the multinomial terms in the inner sum until the total surpasses the target rank ($r$). At this point, the current symbol ($j$) is appended to the block's sequence, and the process moves on to the next iteration of the outer sum. \vspace{0.4cm}

\noindent Algorithm \ref{alg:base4unrank} provides a pseudocode implementation of this unranking process for a sequence based on a base-4 number system. The function prints the sequence of symbols in the block with rank $r$ among the class of blocks with symbol counts $d_0$, $d_1$, $d_2$, and $d_3$

\begin{algorithm}[h!]
    \caption{Base-4 block \emph{unranking} algorithm}
    \label{alg:base4unrank}
    \begin{algorithmic}
        \Function{Base4BlockUnrank}{$r$, $d_0$, $d_1$, $d_2$, $d_3$}
        \State $b \gets d_0 + d_1 + d_2 + d_3$ \Comment{Block size}
        \State $s \gets 0$ \Comment{Blocks counted so far}
        \For{$i = 0$ to $b-1$}
        \For{$j = 0$ to $3$} \Comment{$0$ to $\sigma - 1$}
        \State $d_j \gets d_j - 1$
        \State $count \gets \binom{b - 1 - i}{d_0, d_1, d_2, d_3}$
        \State $d_j \gets d_j + 1$
        \If{$s + count > r$}
        \State print $j$
        \State $d_j \gets d_j - 1$
        \State \textbf{break}
        \Else
        \State $s \gets s + count$
        \EndIf
        \EndFor
        \EndFor
        \EndFunction
    \end{algorithmic}
\end{algorithm}
