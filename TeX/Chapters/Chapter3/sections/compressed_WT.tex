\clearpage
\section{Compressed Wavelet Trees}
In order to make the wavelet tree more space efficient, we ask ourselves if we can compress this data structure. The answer is yes, and in this section we will see how a wavelet tree can be compressed to the zero-order entropy of the input string, while still being able to answer rank and select queries in $O(\log \sigma)$ time. The literature on this topic mainly focus one two different approaches: compressing the bitvectors and altering the shape of the wavelet tree itself.

\subsection{Compressing the bitvectors}
In \cite{GrossiWT2003} Grossi et. al showed that if the bitvectors of each single node are compressed to their zero-order entropy, then their overall space occupance is $n H_0(S)$. So if we suppose that the bitmap associated to the root node has a skewed distribution of $0$s and $1$s, then the zero-order compressing it yields a space of
\begin{equation}
    n_0 \log \frac{n}{n_0} + n_1 \log \frac{n}{n_1}
\end{equation}
where $n_0$ and $n_1$ are the number of $0$s and $1$s in the bitmap, respectively. This is the same as the zero-order entropy of the bitmap. The same reasoning can be applied to the bitmaps of the children of the root node, and so on. This way, one can easy prove by induction \cite{navarro2016compact} that the overall space of the wavelet tree is
\begin{equation}
    \sum_{c \in \Sigma} n_c \log (\frac{n}{n_c}) = n H_0(S)
\end{equation}
% However, to this quantity we must add the redundancy, i.e the space occupied by the pointers of the tree. This redundancy is $o(n \log \sigma)$. Thus bringing the space occupance of the wavelet tree to $n H_0(S) + o(n \log \sigma)$.\todo{I'm not sure that this is true, navarro says that there should be also a $+ O(\sigma w)$ term, but I don't know where it comes from.} \vspace{0.4cm}

\noindent We can now choose from the literature any zero-order entropy coding method for the bitvectors that supports rank and select queries in $O(1)$ time. Some of the most popular methods are RRR \cite{RRR2002} that we have vastly discussed in \autoref{sec:bitvectors}, that for each bitvector of length $n$ uses $n H_0(B) + o(n \log \log n / \log n)$ bits. In \cite{patrascu2008succincter} the authors showed\footnote{In this case, the time complexity of rank and select queries is $O(c)$.} that this value can be further reduced to $n H_0(B) + o(n/\log^c n)$ for any positive constant $c$.

\subsection{Huffman-Shaped Wavelet Trees}
Since working in practice with compressed bitvectors can be less efficient then in theory, we want a method for still obtaining nearly zero-order entropy compression, but while maintaining the bitvectors in plain form. The key idea for the compression method that we are going to analyze is that, as noted by Grossi et. al in \cite{grossi2004indexing}, the shape of the wavelet tree has no impact on the space occupance of the structure. They proposed to use this fact to alter the shape of the tree in order to optimize the average query time. Recalling how we built an Huffman Tree in \ref{subsec:huffman_coding}, we can adapt the same idea to the wavelet tree: given the frequencies $f_c$ with which each leaf node appears in the tree, we can create an Huffman-shaped wavelet tree, obtaining an average access time of
\begin{equation}
    \sum_{c \in \Sigma} f_c \log \frac{1}{f_c} \leq \log \sigma
\end{equation}
A counter effect noted by the authors in \cite{grossi2004indexing} is that in the worst case, we could and up with a time complexity of $O(\log n)$, for example in the case of a very infrequent symbol.However, if we choose $i$ uniformly at random from $[1, n]$ then the average access\footnote{And also for $rank_c(S,j)$ or $select_c(S,j)$ with $c = S=[1]$} time is
\begin{equation}
    O(\frac{1}{n} \sum_c f_c |h(c)| = O(1 + H_0(S))
\end{equation}
That is better than the $O(\log \sigma)$ time of the original balanced wavelet tree.

\begin{remark}
    On a further note, if we bound the depth of the Huffman Tree, we can keep worst care access time to $O(\log \sigma)$, with extra $O(n/\sigma)$ bits of redundancy
\end{remark}

\noindent Another possibile approach following the same idea of a Huffman-shaped wavelet tree, proposed in \cite{makinen2004new}, is to use the frequencies with which the symbols appear in the string. If we use this frequencies to build the Huffman Tree, we can then attach to each node $v$ a bitvector $B_v$ in the same way that we would do for the balanced wavelet tree (\ref{alg:build_wt}). In this way, the bits of $B_v$ are the bits of of the path from the root to $v$ in the Huffman Tree, i.e the Huffman codes of the symbols. Let's see the space occupance of this structure. Consider a leaf corresponding to a symbol $c$, at depth $|h(c|)$ (where $h(c)$ is the bitwise Huffman code for $c$), representing $f_c$ symbols. Each of this occurrences leads to a bit in each bitvector that is in the path from the root to the leaf; that is $|h(c)|$ bits. Thus, the occurrences of $c$ lead to $f_c |h(c)|$ bits in total. If we add this values to all the leaves we obtain same number of bits outputted by the Huffman coding of the string, that is
\begin{equation}
    \sum_{c \in \Sigma} f_c |h(c)| \leq n(H_0(S) + 1)
\end{equation}
If we also want to add the space to support the rank and select queries and the tree pointers needed to navigate the tree, we arrive to a space occupance of
\begin{equation}
    n(H_0(S) + 1) + o(n(H_0(S) + 1)) + O(n \log \sigma)
\end{equation}
For the sake of completeness, we also mention that the shape of an Huffman tree is not the only one that can be given to a wavelet tree. In \cite{grossi2012wavelet} Grossi and Ottaviano gave the wavelet the shape of a trie, making it possible to handle a sequence of strings.

\subsection{Higher Order Entropy Coding}

\todo[inline, color=blue!20]{TODO and TBD: Ask Grossi how in depth to go with this section, Ferragina and Manzini in \cite{TheMyriadVirtuesWT} give a very technical explanation of the method. While in \cite{WTForALL} Navarro gives a more high-level explanation. Furthermore, all this methods relies on the BTW transform, which is not covered in this thesis, do I add a section on it?}
